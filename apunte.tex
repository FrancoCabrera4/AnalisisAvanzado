\documentclass[12pt]{article} 
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\newtheorem{theorem}{Teorema}[section]
\newtheorem{definition}{Definición}[section]
\newtheorem{prop}{Propiedad}[section]
\newtheorem{notacion}{Notación}[section]
\newtheorem{colorario}{Colorario}[section]
\newtheorem{observacion}{Observación}[section]
\newtheorem{lema}{Lema}[section]
\begin{document}


\section{Introducción}


\section{Preliminares}

En este primer capítulo vamos a definir todos las nociones fundacionales que se van a utiliizar a lo largo de la materia. Principalmente hay que entender claramente que son las sucesiones, subsucesiones, la convergencia y el límite. Entiendo que pueden sonar como básicas algunas definiciones, mientras que otras son nuevas, pero me parece importante tenerlas todas juntas para saber de donde partimos.

\begin{definition}
    Sea $(a_n)$ una sucesión, entonces una sucesión $(a_{n_k})$ es una subsucesión de la primera si y solo si $(n_k)$ es una sucesión estrictamente creciente de números naturales. Es decir, una subsucesión respeta el orden de la sucesión, pero eventualmente puede omitir algunos términos.
\end{definition}

\begin{definition}
    Sea $(a_n) \subset \mathbb{R}$ una sucesión, se dice que la sucesión converge si existe un $a$ tal que:
    \[
        \forall\epsilon>0, \exists n_0 : | a - a_n | < \epsilon, \forall n\geq n_0
    \]
    Y este $a$ se llama el límite de la sucesión y se nota $\lim_{n\to\infty}a_n = a$
\end{definition}

\begin{definition}
    Sea $A \subset \mathbb{R}$ un conjunto no vacío. Se dice que $c \in \mathbb{R}$ es una cota superior de $A$ si $c \ge x, \forall x \in A$. Un conjunto acotado superiormente es aquel que tiene una cota superior.
\end{definition}

\begin{definition}
    Sea $A \subset \mathbb{R}$ un conjunto no vacío y acotado superiormente. Se dice que $s \in \mathbb{R}$ es supremo de $A$ si cumple:
    \begin{itemize}
        \item $s$ es cota superior de $A$
        \item $\forall t$ cota superior de $A$, $t \ge s$
    \end{itemize}
    Y en ese caso se nota $s = \sup(A)$
\end{definition}

\begin{prop}
    Sea $A \subset \mathbb{R}$ un conjunto no vacío y acotado superiormente. $s \in \mathbb{R}$ es supremo de $A$ si y solo si cumple:
    \begin{itemize}
        \item $s$ es cota superior de A
        \item $\forall \epsilon > 0, \exists a \in A : a > s - \epsilon$
    \end{itemize}
\end{prop}
\begin{proof}
    Si $s$ es supremo entonces ya se verifica la primera de las dos propiedades. Para la segunda procedo por el absurdo, supongo que $\exists \epsilon > 0, \forall a \in A : a \le s - \epsilon$, por lo tanto se cumple que $t = s - \epsilon$ es cota superior de $A$, pero a su vez $t < s$, donde $s$ era supremo de $A$, absurdo, y por lo tanto no existe dicho $\epsilon$ y se demostró lo pedido.

    Para la otra dirección de la equivalencia también tenemos la primera condición dada. Supongo ahora que $\exists t < s$ tal que $t$ es cota superior. Por hipótesis si se fija $\epsilon = s - t, \exists a \in A : a > s - \epsilon = s - (s - t) = t \Rightarrow a > t$, pero se tiene que $t$ es cota superior, absurdo. Y por ende se concluye que $s$ es supremo de $A$.
\end{proof}
\begin{prop}
    Sea $A \subset \mathbb{R}$ un conjunto no vacío y acotado superiormente. Luego $s \in \mathbb{R}$ es supremo de $A$ si y solo si:
    \begin{itemize}
        \item $s$ es cota superior de $A$
        \item $\exists (a_n) \subset A : a_n \rightarrow s$
    \end{itemize}
\end{prop}
\begin{proof}
    Si $s$ es supremo ya se cumple la primera propiedad y usando la equivalencia se tiene que $\forall n \in \mathbb{N}, \exists a_n : a_n > s - \frac{1}{n}$, de donde es claro que la sucesión dada por estos términos cumple $a_n \rightarrow s$. 

    Para la otra dirección, de forma análoga ya se tiene la primera propiedad. Supongo que el supremo no es $s$, sea $t$ el supremo, luego se tiene que $t < s$ y se puede definir $\epsilon = s - t$ y por definición de límite se cumple que $\exists n_0 \in \mathbb{N} : n \ge n_0 \Rightarrow |s - a_n | < \epsilon$ y por lo tanto se cumple que $a_n > s - \epsilon = s - (s - t) = t$, pero $t$ es el supremo de $A$, absurdo. Y se demostró lo pedido.
\end{proof}

Resulta bastante análogo demostrar todas estas definiciones y equivalencias para las cotas inferiores. A modo de ejemplo dejo la definición de ínfimo.

\begin{definition}
    Sea $A \subset \mathbb{R}$ un conjunto no vacío y acotado inferiormente. Luego $i \in \mathbb{R}$ es ínfimo de $A$ si y solo si:
\begin{itemize}
    \item $i$ es cota inferior de $A$
    \item $\forall t$ cota inferior de $A$, $t\leq i$
\end{itemize}

\begin{definition}
    Sea $(a_n) \subset \mathbb{R}$ una sucesión. Se define el límite inferior de la sucesión como:
    \[
        \liminf a_n = \sup_{n\in \mathbb{N}}\inf_{k\geq n}a_k 
    \]
    De manera análogo se define el límite superior de la sucesión como:
    \[
        \limsup a_n = \inf_{n\in \mathbb{N}}\sup_{k\geq n}a_k
    \]
\end{definition}

\begin{observacion}
    Tanto el límite inferior y el límite superior siempre existen, sin importar la convergencia de la sucesión, puesto que se toma el supremo e ínfimo de sucesiones monótonas (eventualmente puede ser $\pm\infty$).
\end{observacion}

\begin{notacion}
    Sea $(a_n) \subset \mathbb{R}$ una sucesion creciente tal que $\lim_{n\to\infty}a_n = a$, luego para indicar que $a_n \rightarrow a$ de manera monótona creciente se nota:
    \[
        a_n \uparrow a
    \]
    De manera análoga si la sucesión es monótona decreciente con $\lim_{n\to\infty}a_n = a$ se nota:
    \[
        a_n \downarrow a
    \]
\end{notacion}

A lo largo de los capítulos vamos a ver que esta notación se extiende de manera natural a sucesiones de conjuntos, funciones y demás.
\section{Cardinalidad}

En esta sección vamos a dedicar un tiempo a pensar y explorar la noción de tamaño o cardinalidad de conjuntos en los que habitualmente no pensamos de esta forma, estos son los conjuntos no finitos. Cuando un conjunto es finito la cantidad de elementos que tiene es naturalmente su cardinal y de esta forma podemos notar que si $A = \{1, 2, 3\}$ entonces $\#A = 3$.

Sin embargo este approach no funciona con los conjuntos no finitos, porque resultaría que todos tendrían cardinal infinito y toda nuestra exploración termina ahí. Pero al encontrar un bloqueo no hay que rendirnos y en este caso una idea muy útil y algo intuitiva es que si no podemos contar algo, podemos intentar contar algo que sea parecido o incluso mejor tenga la misma cantidad de elementos y sí sea facil de contar. Y esa es la idea con la que vamos a empezar, Georg Cantor entendió que no podía contar directamente los elementos de un conjunto, pero al menos sí podía comparlos entre sí.

\begin{definition}
    Sean $X, Y$ dos conjuntos. Decimos que son coordinables (o equipotentes, o de igual cardinal) si existe $f : X \rightarrow Y$ tal que $f$ es biyectiva. Y se suele notar $X \sim Y$
\end{definition}
\begin{prop}
    La relación $\sim$ es una relación de equivalencia.
\end{prop}
\begin{proof}
    Sean $X, Y, Z$ conjuntos tales que $X \sim Y$ y $Y \sim Z$. La identidad es biyectiva para todo conjunto por lo tanto la relación es reflexiva. Si $f : X \rightarrow Y$ es biyectiva, entonces tiene inversa y $f^{-1} : Y \rightarrow X$ es biyectiva y se sigue que la relación es simétrica. Si $g : Y \rightarrow Z$ es biyectiva se tiene que la composición $z = g \circ f, z : X \rightarrow Z$ es biyectiva y por tanto la relación es transitiva. Teniendo estas tres propiedades se sigue que la relación es de equivalencia.
\end{proof}
\begin{definition}
    Un conjunto $A$ se dice numerable si $A \sim \mathbb{N}$. Un conjunto $A$ se dice contable si $A$ es finito o numerable.
\end{definition}
\begin{definition}
    Decimos que $\#X \le \#Y$ si existe $f : X \rightarrow Y$ inyectiva. Luego, decimos que $\#X < \#Y$ si $\#X \le \#Y$, pero $\#X \neq \#Y$ 
\end{definition}

\begin{theorem}
    
\end{theorem}
    Sea $X$ un conjunto, entonces $\#X < \#P(X)$ 
\begin{proof}
    Procedemos por el absurdo y supongamos que esto no es cierto. Y como es claro que la función identidad es inyectiva de $X \rightarrow P(X)$, entonces $X \sim P(X)$. Por lo tanto existe una function biyectiva entre los conjuntos, sea esta $f: X \rightarrow P(X)$. Considero el conjunto $A := \{ a \in X : a \notin f(a) \}$, como claramente $A \in P(X)$ tiene sentido evaluar $f^{-1}(A) = B$. 

    Ahora existen 2 casos, o bien $B \in A$ o $B \notin A$. 

    Caso 1° $B \in A$, entonces $B \notin f(B) = A \Rightarrow B \notin A$. Absurdo

    Caso 2° $B \notin A$, entonces $B \in f(B) = A \Rightarrow B \in A$. Absurdo

    Pero $f$ era una funcion biyectiva, pero sin embargo $f(B)$ no está definida. Por lo tanto la supocisión inicial era incorrecta y se concluye que $\#X < \#P(X)$
\end{proof}

La idea de este conjunto y demostración está acuñada bajo el término de la paradoja de Russel

\begin{theorem}
    Teorema de Schroder-Berstein. Si existen $f: X \rightarrow Y, g: Y \rightarrow X$ inyectivas, entonces existe $h: X \rightarrow Y$ biyectiva.
\end{theorem}

Este teorema va a ser fundamental porque en muchísimos casos encontrar una función biyectiva entre dos conjuntos va a ser bastante complicado, mientras que encontrar un par de funciones inyectivas como las del enunciado no va a ser tan difícil. La prueba es un poco difícil de adquirir a la primera, pero leyendola un par de veces sale.

\begin{proof}
    Sea $A_1 = X \setminus g(Y)$ e inductivamente se define $A_n = g(f(A_{n-1}))$. Afirmo que estos conjuntos son disjuntos dos a dos, para eso procedo por el absurdo y asumo que no es así, entonces $\exists j, i : x \in A_j, x \in A_i$, sin perdida de generalidad asumo que $i < j$. Como $g, f$ son ambas inyectivas se sigue que $\exists y : y \in f(A_{j-1}), y \in f(A_{i-1})$, donde a su vez $\exists k : k \in A_{j-1}, k \in A_{i-1}$. Por lo tanto llevando este argumento a su caso base se tiene que $\exists m : m \in A_1, m \in A_{j + 1 - i}$, pero si $m \in A_1 \Rightarrow m \notin g(Y)$, donde a su vez si $m \in A_{j + 1 - i} \Rightarrow m \in g(Y)$, absurdo. 

    Por lo tanto sea $A = \cup A_n, B = \cup f(A_n)$, se sigue que $f: A \rightarrow B$ es una función biyectiva. Luego sea $A' = X \setminus A, B' = Y \setminus B$, es claro que $g: Y \rightarrow g(Y)$ es biyectiva por definición, entonces $g(B') = g(Y \setminus B) = g(Y) \setminus g(B) =  A'$

    Finalmente se tiene que la función $h: X \rightarrow Y$ es biyectiva y cumple lo pedido 
    \[
       h(x) := \begin{cases}
           f(x) & x \in A \\
           g^{-1}(x) & x \in X \setminus A
       \end{cases} 
    \]

\end{proof}

Revisar esta última demo

\begin{prop}
    Sea $\{ A_n \}$ una familia numerable de conjuntos numerables, entonces $A = \cup A_n$ es un conjunto numerable.
\end{prop}

\begin{proof}
    Hay dos formas bastante intuitivas de demostrar esta propiedad: una es usar el argumento de diagonalización de Cantor y la otra es usar el teorema de Schroder-Berstein. En ambas surge a primera vista que es "incómodo" que los conjuntos $A_n$ no son disjuntos dos a dos, ya que esto mata a los argumentos porque vamos a encontrar, potencialmente, elementos repetidos. 

    Teniendo esto en cuenta sea $\{ B_n \}$ una familia contable de conjuntos definidos por: $B_1 = A_1, B_2 = A_2 \setminus A_1$, y de forma general $B_n = A_n \setminus (\cup_{i=1}^{n-1}A_i)$. Por construcción resulta claro que $\cup_{n=1}^{\infty}B_n = \cup_{n=1}^{\infty}A_n$ y que $i\neq j \Rightarrow B_i \cap B_j = \emptyset$. Sea $f(n) = B_{1n}$ y $g(B_{ij}) = p_i^{j}$, donde  $p_i = i$-ésimo número primo y $B_{ij} \in B$. Como ambas funciones son inyectivas, utilizando el teorema de Schroder-Berstein, que $A \sim \aleph_0$.
\end{proof}

\begin{theorem}[Teorema de diagonalización de Cantor]
    El conjunto de los números reales $\mathbb{R}$ no es numerable.
\end{theorem}
\begin{proof}
    Supongamos por el contrario que lo es, entonces existe una sucesión $(a_n)_{n\in \mathbb{N}}$ que contiene a todos los números reales. Expandamos esta sucesión en su expresión decimal de forma que:
    \[
    \begin{array}{cccccccc}
        a_1 & = & d_{11} & d_{12} & d_{13} & d_{14} & d_{15} & \cdots \\
        a_2 & = & d_{21} & d_{22} & d_{23} & d_{24} & d_{25} & \cdots \\
        a_3 & = & d_{31} & d_{32} & d_{33} & d_{34} & d_{35} & \cdots \\
        a_4 & = & d_{41} & d_{42} & d_{43} & d_{44} & d_{45} & \cdots \\
        a_5 & = & d_{51} & d_{52} & d_{53} & d_{54} & d_{55} & \cdots \\
    \end{array}
    \]
    Considero entonces al número real $b$ dado en expresión decimal por:
    \[
        b_i = \begin{cases}
            5 & d_{ii} \neq 5 \\
            4 & d_{ii} = 5
        \end{cases}
    \]
    Por construcción se sigue que $b \neq a_i, \forall i\in \mathbb{N}$, es decir $b$ no está en la sucesión, pero $b$ es un número real, ¡absurdo! Por lo tanto se concluye que $\#\mathbb{R} > \aleph_0$.
\end{proof}

Como ya vimos existen cardinales más grandes que otros, y se puede probar (es un ejercicio para hacer) que el cardinal de $\mathcal{P}(\mathbb{N})$ es igual al cardinal de $\mathbb{R}$. Cantor pensaba, cosa que no pudo demostrar, que no había otro cardinal $\aleph_1$ que cumpliera $\aleph_0 < \aleph_1 < c$ y está suposición se la acuño hipótesis del continuo. Tiempo después se demostraría que este resultado es indemostrable, es decir, partiendo de los axiomas y definiciones que fuimos planteando la existencia o no de tal cardinal resulta logicamente compatible en cualquier caso con el sistema. 
\begin{prop}[Hipótesis del continuo de Cantor]
    No existe otro cardinal $\aleph_1$ tal que cumpla:
    \[
        \aleph_0 < \aleph_1 < c
    \]
\end{prop}

\section{Espacios Métricos}

\begin{definition}
   Espacio métrico. Sea $E$ un conjunto. Una función $d: E \times E \rightarrow \mathbb{R}$ se llama una métrica o una distancia sobre $E$ si se cumple: 
   \begin{itemize}

       \item $d(x, y) = 0 \iff x = y$
       \item $d(x, y) = d(y, x), \forall x, y \in E$
       \item $d(x, y) \leq d(x, z) + d(z, y), \forall x, y, z \in E$
       
   \end{itemize}
\end{definition}

\begin{definition}
    Se define a la distancia euclídea $d_2$ para $x, y \in \mathbb{R}^n$ como: 
    \[
        d_2(x, y) = (\sum_{i=1}^{n} (x_i - y_i)^{2})^{\frac{1}{2}} = \parallel x - y \parallel_2
    \]
\end{definition}

\begin{definition}
    De forma más general se va a definir la norma n en $\mathbb{R}^n$ como:
    \[
        d_n(x, y) = (\sum_{i=1}^{n} (x_i - y_i)^{n})^{\frac{1}{n}} = \parallel x - y \parallel_n
    \]
    Con la particularidad de que también se define la norma infinito como:
    \[
        d_{\infty}(x, y) = max_{1\leq i \leq n} \{|x_i - y_i|\}
    \]
    Siendo esto así porque este es el límite de las distancias cuando n se va a infinito
\end{definition}

\begin{definition}
    Dado un intervalo cerrado $[a, b] \subset \mathbb{R}$, se denota $C([0, 1])$ al conjunto de todas las funciones $f: [a, b] \rightarrow \mathbb{R}$ al conjunto de todas las funciones $f: [a, b] \rightarrow \mathbb{R}$ continuas.
\end{definition}

\begin{definition}
    Este conjunto tiene dos distancias intuitivas: la infinito y la uno. Se definen como:
    \[
        d_{\infty}(f, g) = sup_{a\leq t\leq b} |f(t) - g(t)|
    \]
    \[
        d_1(f, g) = \int_{a}^{b} |f(t) - g(t)|
    \]
\end{definition}

\begin{definition}
    Sea $E$ un conjunto cualquiera. Definimos la distancia discreta en $E$ como:
    \[
        \delta(x, y) = \begin{cases}
            0 & x = y \\
            1 & x \neq y
        \end{cases}
    \]
\end{definition}

\begin{definition}
    Dados $x \in E$ y $r > 0$, la bola abierta de centro $x$ y radio $r > 0$ es el conjunto definido por: 
    \[
        B(x, r) = \{y \in E : d(x, y) < r\}
    \]
\end{definition}

\begin{definition}
    Dados $x\in E$ y $r > 0$, la bola cerrada de centro $x$ y radio $r$ es el conjunto:
    \[
        \bar{B}(x, r) = \{y\in E : d(x, y) \leq r \}
    \]
\end{definition}

\begin{definition}
    Sea $A \subset E$. Decimos que $x$ es un punto interior de $A$ si existe algún $r>0$ tal que $B(x, r) \subset A$
\end{definition}

\begin{definition}
    Sea $A \subset E$. El interior de $A$ es el conjunto de todos los puntos interiores de $A$, y se lo nota $A^{\circ}$
\end{definition}

\begin{definition}
    Un conjunto $G \subset E$ se dice abierto si cada punto de $G$ es un punto interior de $G$, es decir si $G = G^{\circ}$
\end{definition}

\begin{theorem}
    Sea $\{ A_n \}$ una familia de conjuntos abiertos, entonces $A = \cup A_n$ es un conjunto abierto. Además si la familia es finita, $B = \cap A_n$ también es abierto.
\end{theorem}

\begin{proof}
    Sea $y \in A$, luego en particular $\exists i : y \in A_i$ y como $A_i$ es un conjunto abierto se tiene que $\exists\epsilon > 0 : B(y, \epsilon)\subset A_i \subset A$, por lo tanto $y$ es un punto interior de $A$ y se concluye que $A$ es un conjunto abierto. 

    Sea $y\in B$, luego $\exists r_1, r_2, \cdots, r_N : B(y, r_1)\subset A_1, B(y, r_2)\subset A_2, \cdots, B(y, r_N)\subset A_n$. Sea $r = \min\{r_i, 1\leq i\leq N\}$, entonces vale que $B(y, r) \subset A_i, 1\leq i \leq N \Rightarrow B(y, r) \subset \cap_{i=1}^{N}A_i = B$, es decir $y$ es un punto interior de $B$ y por lo tanto $B$ es un conjunto abierto.

\end{proof}

\begin{definition}
    Un conjunto $V \subset E$ se llama entorno de $x$ si existe un conjunto abierto $G$ tal que $x \in G \subset V$
\end{definition}

\begin{definition}
    Se dice que $x$ es un punto de adherencia del conjunto $A \subset E$ si para todo $r > 0$, $A \cap B(x, r) \neq \emptyset$
\end{definition}

\begin{definition}
    Se dice que $x$ es un punto de acumulación del conjunto $A \subset E$ si para todo $r > 0$, el conjunto $A\cup B(x, r)$ es un conjunto infinito.
\end{definition}

\begin{definition}
    La clausura de $A \subset E$ es el conjunto $\bar{A}$ formado por todos los puntos de adherencia del conjunto $A$
\end{definition}

\begin{definition}
    Un conjunto $F$ se llama cerrado si $F = \bar{F}$
\end{definition}

\begin{theorem}
    Un conjunto $A$ es cerrado si y solo si $A^{c}$ es abierto.
\end{theorem}
\begin{proof}
    $\Rightarrow)$ Supongamos que $A^{c}$ no es un conjunto abierto, luego $\exists a \in A^{c} : \forall r>0, B(x, r)\not\subset A^{c}$, es decir, $\forall r>0, \exists y_r \in A : y\in B(a, r)$. Considero entonces la sucesión $(y_n) \subset A : y_n \in B(a, \frac{1}{n})$, resulta entonces que $y_n \rightarrow a$, y como $A$ es un conjunto cerrado toda sucesión convergente converge en el conjunto, es decir, $a\in A$, ¡absurdo! Puesto que por hipótesis $a\in A^{c}$. Se concluye, entonces, que $A^{c}$ es un conjunto abierto.

    $\Leftarrow)$ Si $A$ no es cerrado, $\exists (y_n) \subset A : y_n \rightarrow y \not\in A$, es decir, $y\in A^{c}$. Entonces $\forall r>0, \exists y_n : y_n \in B(y, r) \Rightarrow B(y, r)\not\subset A^{c}$, es decir, $y$ no es un punto interior de $A^{c}$ y por lo tanto no es un conjunto abierto, ¡absurdo!. Por lo tanto $A$ es cerrado.
\end{proof}
\begin{theorem}
    Sea $\{ A_n \}$ una familia de conjuntos cerrados. Si la familia es finita, entonces $A = \cup A_n$ es un conjunto cerrado.
\end{theorem}
\begin{proof}
    Consiero $(\cap A_n^{c})^{c}$, como la intersección finita de conjuntos abiertos es abierta se tiene que ese conjunto es cerrado. Además, por las leyes de De Morgan se tiene:
    \[
        (\bigcap A_n^{c})^{c} = \bigcup (A_n^{c})^{c}) = \bigcup A_n = A
    \]
\end{proof}

\begin{definition}
    Dada un conjunto $A$, el conjunto de puntos de acumulación de $A \subset E$ se denomina conjunto derivado de $A$, y se lo nota:
    \[
        A' = \{ x\in E : x \text{ es punto de acumulación de } A \}
    \]
\end{definition}

\begin{definition}
    Dado $A \subset E$, se dice que $x$ es un punto de la frontera de $A$ si para todo $r>0$, se cumple:
    \[
        B(x, r) \cap A \neq \emptyset, B(x, r) \cap A^{c} \neq \emptyset
    \]
    Al conjunto de los puntos frontera se lo nota $\partial A$
\end{definition}

\begin{definition}
    Decimos que una sucesión $(x_n)_{n\in \mathbb{N}} \subset E$ converge a $x \in E$ si dado cualquier $\epsilon > 0$ existe un $n_0 \in \mathbb{N}$ tal que $d(x, x_n) < \epsilon, \forall n \geq n_0$ 
\end{definition}

\begin{definition}
    Dado un conjunto $A \subset E$, un punto $x \in A$ se dice aislado si existe $r>0$ tal que $B(x, r) \cap A = \{ x \}$
\end{definition}

\begin{definition}
Dado un conjunto $A \subset E$, se dice que es acotado si existen $x\in E, r>0$ tal que $A \subset B(x, r)$
\end{definition}

\begin{definition}
    Una sucesión $(x_n)_{n\in \mathbb{N}}$ se dice acotada si se encuentra contenida en un conjunto acotado. Es decir, $\forall n \in \mathbb{N} : a_n \in A$, donde $A$ es un conjunto acotado.
\end{definition}

\begin{definition}
    Una sucesión $(x_n)_n$ se dice de Cauchy si para todo $\epsilon > 0$ existe $n_0 \in \mathbb{N}$ tal que si $n, m \geq n_0$, entonces $d(x_n, x_m) < \epsilon$
\end{definition}

\begin{theorem}
    Sea $(E, d)$ un espacio métrico y $(x_n)_n \subset E$, luego:
    \begin{itemize}
        \item Si $(x_n)_n$ es de cauchy, entonces es acotada
        \item Si $(x_n)_n$ es convergente, entonces es de cauchy
        \item Si $(x_n)_n$ es de cauchy y tiene alguna subsucesión convergente, entonces $(x_n)_n$ es convergente. 
    \end{itemize}
\end{theorem}
\begin{proof}
    Por ser sucesión de Cauchy en particular para $\epsilon = 1, \exists n_0 : d(x_n, x_{n_0}) < 1, \forall n\geq n_0$. Sea $R = \max\{d(x_1, x_{n_0}), d(x_2, x_{n_0}), \cdots, d(x_{n_0 -1}, x_{n_0}), 1\}$. Luego $x_n \in B(x_{n_0}, R), \forall n\in \mathbb{N}$, es decir $(x_n)$ está acotada.

    Si $x_n\rightarrow x$, entonces $\forall \epsilon > 0, \exists n_0 : d(x_n, x) < \frac{\epsilon}{2}, \forall n\geq n_0$. Por lo tanto dado $n, m \geq n_0$ se tiene: 
    \[
        d(x_n, x_m) \leq d(x_n, x) + d(x, x_m) \leq \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon
    \]
    Es decir, $(x_n)$ es de Cauchy.
    
    Sea $(x_{n_j}) \rightarrow x\in E$ la subsucesión convergente. Luego dado $\epsilon > 0, \exists n_0 : d(x_{n_j}, x) < \frac{\epsilon}{2}, \forall j \geq n_0$. Por ser de Cauchy existe $n_1 : d(x_n, x_m) < \frac{\epsilon}{2}, \forall n, m\geq n_1$. Sea $n_3 = \max\{n_0, n_1\}$, luego:
    \[
        d(x_n, x) \leq d(x_n, x_{n_{n_3}}) + d(x_{n_{n_3}}, x) \leq \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon, \forall n\geq n_3
    \]
    Por lo tanto $x_n \rightarrow x$ y la sucesión es convergente.
\end{proof}
\begin{definition}
    Un espacio métrico $(E, d)$ se dice completo si toda sucesión de cauchy es convergente a algún punto $x \in E$
\end{definition}

\section{Funciones Continuas}
    El primer acercamiento que diría todos tienen al concepto de funciones continuas está capturado en la frase "las funciones que no dan salto" o "se pueden dibujar sin levantar el lápiz", esto está bien para el contexto donde se presenta, pero a esta altura ya vimos lugares donde esa definición no sirve, por ejemplo una función $f: \mathbb{R} \rightarrow \mathbb{R}^2$. Por eso se trabaja con la definición de epsilon-delta, y en esta sección se van a presentar todo el resto de herramientas iniciales para trabajar con este tipo de funciones en todos los espacios métricos. 

\begin{definition}
    Una función $f: E \rightarrow E'$ se dice continua en el punto $x \in E$ si para cada $\epsilon > 0$ existe $\delta > 0 $ tal que
    \[
        y \in E, d(x, y) < \delta \Rightarrow d'(f(x), f(y)) < \epsilon
    \]
    O equivalentemente utilizando la definición topológica, para cada $\epsilon > 0$ existe $\delta > 0$ tal que 
    \[
        f(B(x, \delta)) \subset B(f(x), \epsilon)
    \]
\end{definition}

Honestamente para mi esta es la mejor equivalencia de continuidad para una función, que las sucesiones convergentes, convergen a donde uno esperaría en la imagen. 
\begin{theorem}
    Una función $f: E \rightarrow E'$ es continua en $x$ si y solo si transforma cualquier sucesión convergente a $x$ en una sucesión convergente a $f(x)$
\end{theorem} 
\begin{proof}
    $\Rightarrow)$ $f$ es continua y sea $(a_n)_{n \in \mathbb{N}} \subset E$ una sucesión tal que $\lim_{n\to\infty} a_n = a \in E$. Dado $\epsilon > 0$, como $f$ es continua en particular lo es en $x$ y por lo tanto existe $\delta > 0$ tal que $f(B(x, \delta)) \subset B(f(x), \epsilon)$. A su vez como la sucesión converge a $x$ existe un $n_0$ tal que $x_n \in B(x, \delta), \forall n \geq n_0$. Uniendo ambas partes resulta que si $n \geq n_0$ entonces $x_n \in B(x, \delta) \Rightarrow f(x_n) \in f(B(x, \delta)) \Rightarrow f(x_n) \in B(f(x), \epsilon)$ y por lo tanto $\lim_{n\to\infty}f(x_n) = f(x) \\$

    $\Leftarrow)$ Supongo que $f$ no es continua, luego $\exists \epsilon > 0 : \forall \delta > 0, f(B(x, \delta)) \not\subset B(f(x), \epsilon)$, por lo tanto para cada $n \in \mathbb{N}$ se cumple que $\exists y_n : y_n \in B(x, \frac{1}{n}), y_n \not\in B(f(x), \epsilon)$ , pero esto significa que $y_n \rightarrow x, f(y_n) \not\rightarrow f(x)$, lo cual es un absurdo por hipótesis. Por lo tanto se concluye que $f$ es continua.
\end{proof}

Incluir 2 imagenes, una con una función discontinua en el plano, y una de una superficie que muestre que toda sucesión converge a donde uno espera.

\begin{notacion}
    Dada una función $f: E \rightarrow E'$ y un conjunto $A \subset E'$ se define la preimagen de A como
    \[
        f^{-1}(A) := \{ x \in E : f(x) \in A \}
    \]
    Es importante notar que esto NO es la inversa de la función porque esta podría no existir.

\end{notacion}

Esta es la definición de adultos de continuidad y la que les gusta a los matemáticos, todavía no encontré el amor que se le tiene, pero sí hay que reconocer que es una herramienta útil.

\begin{theorem}
    Una función $f: E \rightarrow E'$ es continua si y sólo si la preimagen de todo abierto de $E'$ es un abierto en $E$.
\end{theorem}
\begin{proof}
$\Rightarrow)$ $f$ es continua y sea $A' \subset E'$ un conjunto abierto, y se define $A = f^{-1}(A')$. Sea $x \in A$, como $A'$ es un conjunto abierto y $f(x) \in A'$ entonces $\exists\epsilon$ tal que $B(f(x), \epsilon) \subset A'$. Luego como $f$ es continua $\exists\delta>0 : f(B(x, \delta)) \subset B(f(x), \epsilon) \subset A' \Rightarrow B(x, \delta) \subset A$, y por lo tanto se tiene que $x$ es un punto interior de $A$, y como $x$ era un punto arbitrario se concluye que $A$ es un conjunto abierto. \\

$\Leftarrow)$ Sea $x \in E$ un punto, es claro que $f(x) \in E'$ y dado $\epsilon>0$ considero el abierto de la bola dado por $B(f(x), \epsilon)$, luego por hipótesis, $f^{-1}(B(f(x), \epsilon)$ es un abierto y por ende dado un punto interior $x$, $\exists\delta>0 : B(x, \delta) \in f^{-1}(B(f(x), \epsilon) \Rightarrow f(B(x, \delta) \subset B(f(x), \epsilon)$ y por lo tanto $f$ es continua.
\end{proof}

\begin{theorem}
    Una función $f: E \rightarrow E'$ es continua si y solo si para todo $A \subset E$ se cumple $f(\overline{A}) \subset \overline{f(A)}$. 
\end{theorem}
\begin{proof}
    $\Rightarrow)$ Sea $y \in f(\bar{A})$, entonces $\exists x\in \bar{A} : f(x) = y$, y además por pertenecer a la clausura se tiene que $\exists (x_n)_{n\in \mathbb{N}} \subset A: x_n \rightarrow x$. Luego ya que $f$ es continua, $f(x_n) \subset f(A) : f(x_n) \rightarrow f(x)$, y nuevamente, como existe una sucesión en el conjunto que converge a un punto, se deduce que ese punto pertenece a la clausura y por ende $f(x) \in \overline{f(A)} \Rightarrow y \in \overline{f(A)} \Rightarrow f(\bar{A}) \subset \overline{f(A)}$ \\

    $\Leftarrow)$ Sea $F \subset E'$ un conjuto cerrado y sea $A = f^{-1}(F)$. Luego $\bar{A} = \overline{f^{-1}(F)} \Rightarrow f(\bar{A}) \subset \overline{f(A)} \subset \overline{F} = F$. Con esto se tiene que $f(\bar{A}) \subset F \Rightarrow f^{-1}(f(\bar{A})) \subset f^{-1}(F) \Rightarrow \bar{A} \subset A$. Por lo tanto $A$ es un conjunto cerrado, es decir la preimagen de un cerrado cualquiera es un conjunto cerrado, esto quiere decir que $f$ es continua.
\end{proof}

Con este último teorema se completan las equivalencias básicas de continuidad que van a ser las herramientas que vamos a tener a la hora de atacar problemas. Pero hay un concepto importante más que ver antes de terminar la sección y este es: continuidad uniforme. Además nos va a servir en las secciónes siguientes cuando profundicemos en sucesiones. La idea no es muy complicada, ya vimos cuando una función es continua, pero ahora vamos a ver que hay puntos donde es más "inmediatamente continua" que en otros. Por ejemplo, si pensamos en $f: (0, +\infty) \rightarrow \mathbb{R}, f(x) = \frac{1}{x}$, es claro que $f$ es continua, pero dado un epsilon, mientras más cerca del $0$ fijemos al $x$ más difícil va a ser encontrar al $\delta$ que sirva. (REVISAR TEXTO)

\begin{definition}
    Una funcion $f: E \rightarrow E'$ se dice uniformemente continua si dado $\epsilon > 0$ existe $\delta > 0$ tal que:
    \[
        d(x, y) < \delta \Rightarrow d'(f(x), f(y)) < \epsilon, \forall x \in E
    \]
    O equivalentemente, en su versión topológica:
    \[
        f(B(x, \delta)) \subset B(f(x), \epsilon), \forall x\in E
    \]
\end{definition}

\begin{prop}
   Sea $f: E \rightarrow E'$. Entonces, $f$ NO es uniformemente continua si y solo si existen $\epsilon_0$ y sucesiones $(x_n)_n, (y_n)_n \subset E$:
   \[
       d(x_n, y_n) \rightarrow 0, d(f(x_n), f(y_n)) \geq \epsilon_0
   \]
\end{prop} 

Para el manejo de esta definición la siguiente proposición es muy importante saber negar cuantificadores, porque el problema puede parecer más complicado de lo que es si no se hace la negación correcta. 

\begin{proof}
    $\Rightarrow)$ Si $f$ no es uniformemente continua, $\exists\epsilon_0 > 0, \forall\delta>0, \exists x\in E : f(B(x, \delta)) \not\subset B(f(x),\epsilon) \Rightarrow \exists y \in E : d(x, y) <\delta, d'(f(x), f(y)) \geq \epsilon_0$. Por lo tanto para cada $n \in \mathbb{N}$ se puede fijar $\delta = \frac{1}{n}$ y se obtienen dos sucesiones $(x_n), (y_n)$ que cumplen $d(x_n, y_n) < \frac{1}{n}, d(f(x_n), f(y_n)) \geq \epsilon_0$. Es decir:
    \[
        d(x_n, y_n) \rightarrow 0, d(f(x_n), f(y_n)) \geq \epsilon_0
    \]
    \\
    $\Leftarrow)$ Por hipótesis $\exists \epsilon_0 > 0, \forall\delta > 0, \exists n_0 \in \mathbb{N} : f(B(x_{n_0}, \delta)) \not\subset B(f(x_{n_0}), \epsilon)$, puesto que $\exists y_{n_0} \in B(x_{n_0}, \delta) : y_{n_0} \not\in B(f(x_{n_0}), \epsilon)$ y por lo tanto se concluye que $f$ no es uniformemente continua.
\end{proof}

\begin{definition}
    Una función $f: E \rightarrow E'$ se llama homeomorfismo si es biyectiva, continua y su inversa es continua. Consecuentemente dos espacios métricos $(E, d), (E', d')$ se dicen homeomorfos si existe un homeomorfismo $f: E \rightarrow E'$
\end{definition}

Si uno refresca rápidamente la etimología de homeomorfismo se da cuenta que se compone de dos raíces: homoios y morphe. Homoios significa igual o semejante y morphe significa forma o figura. Entonces la pregunta natural para hacerse es: ¿en qué sentido son iguales estos dos espacios? Y la respuesta es en el topológico, porque existe una correspondencia entre los conjuntos de los dos espacios.

\begin{prop}
    Si $E, E'$ son espacios métricos homeomorfos, entonces hay una correspondencia entre los abiertos de $E$ y $E'$
\end{prop}
\begin{proof}
    Si $U \subset E'$ es un conjunto abierto, entonces $V = f^{-1}(U)$ es un abierto ya que la función es continua, y además por ser biyectiva se cumple que $f(V) = U$. Análogamente, si $W \subset E$ es un abierto, entonces $Z = f(W)$ es un abierto por ser la inversa de f una función continua, y además por ser biyectiva se tiene que $f^{-1}(Z) = W$. Con esto probamos que hay una biyección entre los abiertos de $E$ y $E'$
\end{proof}

\begin{definition}
    Si $f: E \rightarrow E'$ satisface $d(x, y) = d'(f(x), f(y))$ se dice que $f$ es una isometría.
\end{definition}

Nuevamente tiene sentido preguntarnos por la etimología, pero en este caso es un poco más obvia. Iso proviene de isos, que significa igual o lo mismo y metría viene de metron, que significa medida. Por lo tanto isometría significa de igual medida. Es decir, una isometría es una función que respeta y no altera la distancia entre puntos y las de sus imagenes.

\section{Conjuntos Compactos}

Ya entendemos lo que es un espacio métrico y tenemos diversas herramientas para clasificar y entender los distintos tipos de conjuntos y como interactuan con las funciones, es decir, que propiedades tienen. En las siguientes dos secciones vamos a desarrollar en mayor profundidad dos tipos de conjuntos que son habituales y aparecen a menudo en muchas aplicaciones.

\begin{definition}
    Sea $(E, d)$ un espacio métrico. Se dice que un subconjunto $K \subset E$ es un conjunto compacto si toda sucesión en $K$ tiene una subsucesión convergente en $K$. En otras palabras, $K$ es compacto si y solo si $\forall (x_n) \subset K, \exists (x_{n_j}) \subset K : \lim_{j\to\infty} x_{n_j} = x \in K$
\end{definition}

\begin{prop}
    Sea $K \subset E$ compacto, entonces $K$ es cerrado y acotado. 
\end{prop}
\begin{proof}
    Si $K$ no es acotado dado $x_0 \in K$, luego $\forall n\in \mathbb{N}, \exists x_n : d(x_n, x_0) \geq n$ y como $(x_n) \subset K$ es una sucesión en $K$ tiene una subsucesión convergente. Sea $(x_{n_j}) \rightarrow x$. Esto significa que $\lim_{j\to\infty} d(x_{n_j}, x) = 0$ y a su vez se cumple que $n_j \leq d(x_0, x_{n_j}) \leq d(x_0, x) + d(x, x_{n_j}) \Rightarrow \lim_{j\to\infty} n_j \leq \lim_{j\to\infty} d(x, x_{n_j}) \Rightarrow +\infty \leq 0$, absurdo! Por lo tanto $K$ es acotado. \\

    Sea $(x_n) \subset K$ una sucesión convergente, luego por ser $K$ compacto $\exists (x_{n_j}): (x_{n_j}) \rightarrow x \in K$, pero como $(x_n)$ ya era convergente toda subsucesión converge al mismo límite y por ende $(x_n) \rightarrow x \in K$ y con esto se concluye que $K$ es cerrado.
\end{proof} 

\begin{theorem}
    Teorema de Heine-Borel. Un conjunto $K \subset \mathbb{R}^{m}$ es compacto si y solo si es un conjunto cerrado y acotado
\end{theorem}
\begin{proof}
    La implicación derecha es automática por la proposición demostrada antes. Así que hay que demostrar la implicación hacia la izquierda. \\
    Sea $(x_n) \subset K$, como $K$ es acotado también lo es la sucesión. Sea $x_n = (x_n^{1}, x_n^{2}, ..., x_n^{m})$, como $x_n$ esta acotado también lo esta $x_n^{i}, \forall 1 \leq i \leq m$, y en particular lo está $x_n^{1}$, así que por el teorema de Bolzano-Weierstrass existe $x_{n_j}^{1} \rightarrow x^{1}$. Así que ahora podemos considerar a $x_{n_j} = (x_{n_j}^{1}, x_{n_j}^{2}, ..., x_{n_j}^{m})$, y repitiendo el argumento resulta que $x_{n_j}^{2}$ tiene una subsucesión $x_{n_{j_l}}^{2} \rightarrow x^{2}$ y a su vez $x_{n_{j_l}}^{1} \rightarrow x^{1}$ por que toda subsucesión de una sucesión convergente converge al mismo límite. Finalmente utilizando este argumento en las $m$ coordenadas se sigue que existe una subsucesión $x_{n_j_{..._h}} \rightarrow x$ y como $K$ es cerrado se tiene que $x \in K$ y por lo tanto se concluye que $K$ es compacto.
\end{proof}

\begin{theorem}
    Sea $(E, d)$ un espacio métrico, entonces $K \subset E$ es un compacto si y solo si todo $A \subset K$ infinito tiene un punto de acumulación en $K$.
\end{theorem}
\begin{proof}
    $\Rightarrow)$ Sea $A \subset K$ un conjunto infinito, luego existe $B \subset A$ numerable y por ende una sucesión contenida en $B$ y que por tanto está contenida en $A$, es decir, $\exists (x_n) \subset A$ una sucesión de elementos distintos. Como $K$ es compacto, $\exists (x_{n_j}) \rightarrow x \in K$, y justamente porque tiene una sucesión de elementos distintos en $A$ que convergen a él, se sigue que $x$ es un punto de acumulación de $A$. \\
    $\Leftarrow)$ Sea $(x_n) \subset K$, considero al conjunto $A = \{ x_n, n \in \mathbb{N}\}$, si $A$ es finito se sigue que la sucesión es eventualmente constante y por lo tanto tiene una subsucesión constante que converge a ese mismo elemento, es decir, $\exists n_0 \in \mathbb{N} : x_n = n_0, \forall n \geq n_1, n_1 \in \mathbb{N}$ y en este caso se sigue que $K$ es compacto. Si por el contrario $A$ es infinito $\exists (x_{n_j}) \rightarrow x \in K$, donde $x$ es el punto de acumulación, y por ende en este caso también se concluye que $K$ es compacto.
\end{proof}

\begin{definition}
    Sea $(E, d)$ un espacio métrico y $K \subset E$ un conjunto. Un cubrimiento por abiertos de $K$ es una familia $(V_i)_{i\in I}$, $V_i \subset E, \forall i \in I$ de subconjuntos abiertos de $E$ tal que 
    \[
        K \subset \cup_{i\in I} V_i
    \]
\end{definition}

\begin{definition}
    Sea $(E, d)$ un espacio métrico y $K \subset E$ un conjunto. Si $(V_i)_{i\in I}$ forma un cubrimiento de $K$ y existe $i_1, i_2, ..., i_N \in I$ tal que
    \[
        K \subset V_{i_1} \cup V_{i_2} \cup ... \cup V_{i_N}
    \]
    Se dice que $(V_{i_k})_{k=1}^{N}$ es un subcubrimiento finito de $(V_i)_{i\in I}$
\end{definition}

En la sección de funciones continuas vimos que existen muchas equivalencias para la definición de continuidad en un punto para una función y esto nos dice que a priori uno podría haber empezado con la definición que más le guste y deducir el resto de equivalencias a partir de esta. En general se empieza por la del epsilon-delta porque es la que probablemente más incialmente se ve, pero nada impide cambiar eso. De la misma forma en esta sección introdujimos la compacidad como una propiedad definida por la existencia de subsucesiones convergentes, pero sin embargo, la definición más común y que más le gusta a los matemáticos es la de subcubrimiento finito por abiertos, que se presenta a continuación. No cambia nada en las construcciones que hicimos hasta ahora, pero es importante saberlo.

\begin{theorem}
    Sea $(E, d)$ un espacio métrico, entonces $K \subset E$ es compacto si y solo si todo cubrimiento de $K$ por abiertos admite un subcubrimiento finito.
\end{theorem}

\begin{proof}
    $\Rightarrow)$ Sea $(V_i)_{i\in I}$ un cubrimiento de $K$, y supongo que no admite un subcubrimiento finito. En particular considero un subcubrimiento $(V_{i_j})$ tal que $V_{i_j} \cap K \neq \emptyset, \forall i_j \in I$ y también $\forall i_j, \exists x \in V_{i_j} : x \not\in V_{i_k}, \forall k \neq j$, es decir del cubrimiento elijo un subcubrimiento donde todos los conjuntos tengan al menos algún elemento de $K$ y que no haya conjuntos contenidos en otros. Esto sigue siendo un cubrimiento de $K$ y ahora considero $(x_n) \subset K$ tal que $x_n \in V_{i_n}, x_i \neq x_j, \forall i \neq j$. Ahora como $K$ es compacto se sigue $\exists (x_{n_j}) \rightarrow x \in K$ y digamos sin perdida de generalidad que $x \in V_{i_l}$, como $V_{i_l}$ es abierto $\exists\epsilon > 0 : B(x, \epsilon) \subset V_{i_l}$ y como la sucesión converge a ese punto se sigue que $\exists n_0 : x_{n_j} \in B(x, \epsilon), \forall j \geq n_0$, absurdo! porque solo hay un punto en la sucesión que pertenece a ese conjunto. Por lo tanto el cubrimiento sí admite un subcubrimiento finito.\\
    $\Leftarrow)$ Supongamos que no fuera el caso, luego utilizando la equivalencia de compacto para subconjuntos infinitos, se tiene que $\exists A \subset K$ tal que $A$ es infinito y $A' = \emptyset$, es decir $\forall x \in K, \exists r_x : A \cap B(x, r_x)$ es finito. Ahora por hipótesis, como $K \subset \cup_{x\in K} B(x, r_x)$ existe un subcubrimiento finito tal que $K \subset \cup_{n=1}^{N} B(x_n, r_{x_n})$. Pero entonces $A = K \cap A \subset \cup_{n=1}^{N} B(x_n, r_{x_n}) \cap A = \cup_{n=1}^{N} (B(x_n, r_{x_n}) \cap A)$, pero este último conjunto es una unión finita de conjuntos finitos, es decir $\#A < \aleph_0$, absurdo! puesto que $A$ es un conjunto infinito. Finalmente se concluye que $K$ es compacto.

\end{proof}

\begin{theorem}
    Las funciones continuas preservan la compacidad. Sean $(E, d)$, $(E', d')$ espacios métricos y sea $f: E \rightarrow E'$ una función continua. Si $K \subset E$ es un conjunto compacto, entonces $f(K)$ es compacto en $E'$
\end{theorem}

\begin{proof}
    Sea $(y_n) \subset f(K)$ una sucesión, para cada $y_n, \exists x_n \in E : f(x_n) = y_n$, donde esto genera una sucesión $(x_n) \subset K$, y como $K$ es compacto existe $(x_{n_j}) \rightarrow x \in K$ y como $f$ es continua preserva la convergencia de sucesiones y se tiene que $f(x_{n_j}) \rightarrow f(x) \in f(K)$ y por lo tanto la sucesión original $(y_n)$ posee una subsucesión $(y_{n_j}) \rightarrow y = f(x) \in f(K)$, de lo que se concluye que $f(K)$ es compacto.
\end{proof}

Este resultado es muy útil combinado con el teorema de Heine-Borel, porque nos va a decir que las funciones de la pinta $f: E \rightarrow \mathbb{R}^{n}$ con $E$ un conjunto compacto van a alcanzar un minimo y un máximo 

\begin{prop}
    Sea $K \subset E$ un conjunto compacto y $f: E \rightarrow \mathbb{R}^{m}$, entonces
        \begin{itemize}
            \item $f$ es acotada en $K$, existe una bola que contiene a todos los valores que toma la función en ese conjunto
            \item $f$ alcaza su máximo y su mínimo en $k$
        \end{itemize}
\end{prop}

\begin{theorem}
    Sean $(E, d), (E', d')$ espacios métricos y sea $f: E \rightarrow E'$, si $f$ es continua y $E$ es un conjunto compacto, entonces $f$ es uniformemente continua.
\end{theorem}
\begin{proof}
    Procedo por el absurdo, supongo que $f$ no es uniformemente continua. Por lo tanto $\exists (x_n), (y_n) \subset E : d(x_n, y_n) \rightarrow 0, d'(f(x_n), f(y_n)) \geq \epsilon_0, \epsilon_0$, para algún $\epsilon_0 > 0$. Como $E$ es un compacto, $\exists (x_{n_j})$ subsucesión convergente, de forma que se sigue cumpliendo $d(x_{n_j}, y_{n_j}) \rightarrow 0$, análogamente $\exists (y_{n_{j_k}})$ convergente, de forma que $d(x_{n_{j_k}}, y_{n_{j_k}}) \rightarrow 0$, pero como ambas sucesiones convergen, por álgebra de límites podemos reemplazar por el límite de cada sucesión, es decir, $x_{n_{j_k}} \rightarrow x, y_{n_{j_k}} \rightarrow y \Rightarrow \lim_{k\to\infty} d(x_{n_{j_k}}, y_{n_{j_k}}) = 0 = d(x, y) \Rightarrow x = y$. Ahora, como $f$ es continua respeta la convergencia de sucesiones y por ende $d'(f(x_{n_{j_k}}), f(y_{n_{j_k}})) \rightarrow d'(f(x), f(y)) = 0 \geq \epsilon_0$, absurdo! Se concluye, entonces, que $f$ es uniformemente continua.
\end{proof}
\section{Espacios Normados}

Nos encontramos ahora con otro tipo especial de espacio que es muy común de ver y este es el espacio normado, que como uno esperaría va a aparecer casi siempre cuando trabajemos con $\mathbb{R}^{n}$. La característica fundamental a recordar de estos espacios es que cuentan con una noción de escalar que la norma va a sacar a fuera. 

\begin{definition}
    Sea $E$ un espacio vectorial (sobre $\mathbb{R}^{n}$ o $\mathbb{C}^{n}$. Una función $\| . \|: E \rightarrow [0, +\infty]$ es una norma si verifica las siguientes propiedades
    \begin{itemize}
        \item $\| x + y \| \leq \| x \| + \| y \|$
        \item $\| \lambda x \| \leq | \lambda | \| x \|$
        \item $\| x \| = 0 \iff x = 0$
    \end{itemize}
\end{definition}

\begin{definition}
    Un espacio vectorial con una norma $(E, \| . \|)$ se llama un espacio normado
\end{definition}

\begin{definition}
    Un espacio normado que es completo con la distancia $d(x, y) = \| x - y \|$ se llama espacio de Banach.
\end{definition}

\begin{definition}
    Dadas dos normas $\| . \|_1, \| . \|_2$ en un espacio vectorial, se dicen equivalentes si existen $c, \bar{c} > 0$ tales que
    \[
        c\| x \|_2 \leq \| x \|_1 \leq \bar{c}\| x \|_2
    \]
\end{definition}

\begin{prop}
    La equivalencia de normas es una relación de equivalencia.
\end{prop}
\begin{proof}
    Sean $\| . \|_1, \| . \|_2, \| . \|_3$ normas en un espacio métrico tales que $\| . \|_1 \sim \| . \|_2, \| . \|_2 \sim \| . \|_3$ \\
    La relación es reflexiva puesto que $1\| x \|_1 \leq \| x \|_1 \leq 1\| x \|_1$ \\
    Es simétrica puesto que si existen $c, \bar{c} > 0 : c\| x \|_2 \leq \| x \|_1 \leq \bar{c}\| x \|_2$, entonces $\frac{1}{\bar{c}}\| x \|_1 \leq \| x \|_2 \leq \frac{1}{c}\| x \|_1$ \\
    Es transitiva puesto que si existen $c, \bar{c}, c_1, \bar{c_1}$ tal que $c\| x \|_2 \leq \| x \|_1 \leq \bar{c}\| x \|_2$, $c_1\| x \|_2 \leq \| x \|_3 \leq \bar{c_1}\| x \|_2$, entonces se tiene que $\frac{c_1}{\bar{c}}\| x \|_1 \leq \| x \|_3 \leq \frac{\bar{c_1}}{c}\| x \|_1$ \\
    Por lo tanto se concluye que la relación es de equivalencia.
\end{proof}

\begin{theorem}
    Todas las normas son equivalentes en $\mathbb{R}^{n}$
\end{theorem}
\begin{proof}
    Ya vimos que la relación de equivalencia de normas es una relación, justamente, de equivalencia, así que para demostrar este teorema basta con demostrar que toda norma es equivalente a una específica y se termina la demostración. La norma elegida para esto va a ser la $\| . \|_1$ \\
Sea $\| . \|_t$ una norma arbitraria y $x = x_1e_1 + x_2e_2 + ... + x_3e_3$, luego se tiene que $\| x \|_t = \| x_1e_1 + x_2e_2 + ... + x_ne_n \|_t \leq |x_1|\|e_1\|_t + |x_2|\|e_2\|_t + ... + |x_n|\| e_n \|_t \leq max\{ e_i, 1 \leq i \leq n\}(|x_1| + |x_2| + ... + |x_n|) = K\| x \|_1$ \\
Por otro lado, defino $g: (\mathbb{R}^{n}, \| . \|_1) \rightarrow (\mathbb{R}, | . |)$, resulta que $g$ es continua puesto que $|g(x) - g(y)| = | \| x \|_t - \| y \|_t | \leq \| x - y \|_t \leq K\| x - y \|_1$. Sea $S = \{ x \in \mathbb{R}^{n} : \| x \|_1 = 1 \}$, por el teorema de Heine-Borel $S$ es compacto. Y como $f$ es continua, $f(S)$ alcanza mínimo, sea este mínimo $m$, luego si $x \in \mathbb{R}^{n} \setminus \{ 0 \} \Rightarrow \frac{x}{\| x \|_1} \in S \Rightarrow \| \frac{x}{\| x \|_1} \|_t \geq m \Rightarrow \| x \|_t \geq m\| x \|_1$ y por lo tanto $\| x \|_t \sim \| x \|_1$, el caso donde $x = 0$ es indistinto porque todas las normas, por definición, valen $0$.
\end{proof}

\begin{definition}
    Dados dos espacios vectoriales $V, W$ y una función $f: V \rightarrow W$, se dice que $f$ es un isomorfismo si $f$ es una transformación lineal biyectiva. En este caso se dice que los espacios $V, W$ son isomorfos. Este ocurre si y solo si ambos espacios tienen la misma dimensión.
\end{definition}

\begin{prop}
    Si $E$ es un espacio normado de dimensión $n \in \mathbb{N}$, entonces existen un isomorfismo lineal de $T: E \rightarrow \mathbb{R}^{n}$ y una norma $\mathbb{R}^{n}$ tal que $T$ es una isometría.
\end{prop} 

\begin{proof}
    Como los espacios tienen la misma dimensión, $\exists T: E \rightarrow \mathbb{R}^{n}$ tal que $T$ es un isomorfismo. Sea $z \in \mathbb{R}^{n}$ se define $\| z \|_0 := \| T^{-1}(z) \|_E$. Vamos a demostrar que esto define a una norma y que esta norma cumple ser una isometría. \\
    Si $z=0 \Rightarrow \| 0 \|_0 = \| T^{-1}(0) \|_E = \| 0 \|_E = 0$, puesto que toda transformación lineal manda el $0$ al $0$ y toda norma evaluada en $0$ da $0$. Ademas como $T$ es una biyección no hay otro vector que tenga como imagen al $0$, es decir $\| z \|_0 = 0 \iff z = 0$. \\
    $\| \alpha z \|_0 = \| T^{-1}(\alpha z) \|_E = \| \alpha T^{-1}(z) \|_E = |\alpha|\|T^{-1}(z)\|_E = |\alpha|\|z_0\|$, es decir la función saca escalares por fuera. \\

    $\| x + y \|_0 = \|T^{-1}(x + y)\|_E = \|T^{-1}(x) + T^{-1}(y)\|_E \leq \|T^{-1}(x)\|_E + \|T^{-1}(y)\|_E \leq \|x\|_0 + \|y\|_0$, por lo que se concluye que $T$ es una norma. \\

    Finalmente veamos que es una isometría, $d_0(T(x), T(y)) = \| T(x) - T(y) \|_0 = \| T^{-1}(T(x) - T(y))\|_E = \|T^{-1}(T(x)) - T^{-1}(T(y))\|_E = \| x - y \|_E$
\end{proof}

Esta demostración es un poco rara porque la idea para la construcción de la norma es, a lo menos, algo inesperada que se nos ocurra.

\begin{colorario}
    Todo espacio de normado de dimensión finita es completo, es decir es un espacio de Banach
\end{colorario}

\begin{colorario}
    En un espacio normado de dimensión finita, los conjuntos cerrados y acotados son compactos.
\end{colorario}

\begin{definition}
    Sean $E, F$ dos espacios normados sobre $\mathbb{R}$. Una aplicación $T: E \rightarrow F$ se llama operador lineal continuo si:
    \begin{itemize}
        \item Es una transformación lineal (u operador lineal)
        \item Es una función continua con las métricas que definen las normas
    \end{itemize}
\end{definition}

\begin{definition}
    Decimos que un operador lineal $T: E \rightarrow F$ es acotado si existe $c > 0$ tal que $\|T(x)\|_F \leq c\|x\|_E, \forall x\in E$. Equivalentemente, $T$ es acotado si $sup_{x \in B(0, 1)} \| T(x) \|_F < \infty$
\end{definition}

\begin{theorem}
    Sean $E, F$ espacios normados, y $T: E \rightarrow F$ un operador lineal. Son equivalentes: 
    \begin{itemize}
        \item $T$ es continua en el origen
        \item $T$ es continua en algún punto
        \item $T$ es continua
        \item $T$ es uniformemente continua
        \item $T$ está acotado
    \end{itemize}
\end{theorem}

\begin{proof}
    
    Si $B_E(x, r) = \{y\in E : \| x - y \|_E < r \}$, sea $y = x + y'$, entonces $B_E(x, r) = \{y\in E : \| x - y \|_E = \| x - (x + y') \|_E = \| y' \|_E < r \} = x + B_E(0, r)$


\end{proof}

\section{Sucesiones de Funciones}

Ya a está altura uno debería estar bastante cómodo trabajando con sucesiones, debería entender las nociones de límites, las propiedades de álgebra de límites, los teoremas más imporantes, etc. Sin embargo, hasta ahora solo trabajamos con las sucesiones más intuitivas que uno entiende, las de numeritos, y después se avanzó hacia sucesiones más abstractas en espacios métricos. Sin embargo uno puede analizar sucesiones de cualquier tipo de objecto, siempre y cuando tenga la noción de distancia entre ellos, y un objeto en particular que nos va a interesar estudiar en este contexto van a ser las funciones. En los primeros momentos es un poco confuso porque tratar a las funciones como puntos en un espacio es un concepto chocante al principio.

\begin{definition}
    La sucesión $(f_n)$ de funciones de $A \rightarrow Y$ converge puntualmente a $f: A \rightarrow Y$ si para todo $x \in A$ se cumple: 
    \[
        \lim_{n\to\infty}f_n(x) = f(x)
    \]
    O equivalentemente, $\forall x \in A, \forall \epsilon > 0, \exists n_0 \in \mathbb{N} : d'(f_n(x), f(x)) < \epsilon, \forall n \geq n_0$. Y se suele notar $f_n \rightarrow f$
\end{definition}

\begin{definition}
    La sucesión $(f_n)$ de funciones de $A \rightarrow Y$ converge uniformemente a $f: A\rightarrow Y$ si dado $\epsilon > 0$, existe $n_0 \in \mathbb{N}$ tal que si $n\geq n_0$ se tiene que:
    \[
        d'(f_n(x), f(x)) < \epsilon
    \]
    Para todo $x \in A$. O equivalentemente $\forall \epsilon > 0, \exists n_0 \in \mathbb{N}, \forall x \in A : d'(f_n(x), f(x)) < \epsilon, \forall n \geq n_0$. Y se suele notar $f_n \rightrightarrows f$
\end{definition}

(FUNDAMENTAL INCLUIR IMAGENES DE EJEMPLO ACÁ)

\begin{theorem}
    \label{thm:continuous-function-convergence}
    Si una sucesión $(f_n)$ de funciones continuas de $X$ en $Y$ converge uniformemente a $f: X \rightarrow Y$, entonces $f$ es continua.
\end{theorem}

\begin{proof}
    Dado $\epsilon > 0$, existe $n_0 \in \mathbb{N} : d'(f(x) - f_n(x)) < \frac{\epsilon}{3}, \forall n \geq n_0, \forall x \in X$ y en particular $f_{n_0}$ es continua, por lo que $\exists \delta > 0 : d(x, x_0) < \delta \Rightarrow d'(f_{n_0}(x), f_{n_0}(x_0)) < \frac{\epsilon}{3}$. Por lo tanto si $d(x, x_0) < \delta \Rightarrow d'(f(x), f(x_0)) \leq d'(f(x), f_{n_0}(x)) + d'(f_{n_0}(x), f(x_0)) \leq d'(f(x), f_{n_0}(x)) + d'(f_{n_0}(x), f_{n_0}(x_0)) + d'(f_{n_0}(x_0), f(x_0))< \frac{\epsilon}{3} + \frac{\epsilon}{3} + \frac{\epsilon}{3} = \epsilon$
\end{proof}

\begin{prop}
    Sea $f_n \rightrightarrows f$, con $f_n, f: [a, b] \rightarrow \mathbb{R}$ funciones continuas, entonces:
    \[
        \lim_{n\to\infty}\int_{a}^{b} f_n(t)dt = \int_{a}^{b} f(t)dt
    \]
\end{prop}
\begin{proof}
    Dado $\epsilon > 0, \exists n_0 : | f_n(x) - f(x) | < \frac{\epsilon}{|b - a|}, \forall n \geq n_0, \forall x \in [a, b]$. Además se cumple:
    \begin{align} 
        | \int_{a}^{b} f_n(t)dt - \int_{a}^{b} f(t)dt | = | \int_{a}^{b}[f_n(t) - f(t)]dt | \\ \leq \int_{a}^{b} | f_n(t) - f(t) |dt < \int_{a}^{b} \frac{\epsilon}{|b-a|}dt = \frac{\epsilon (b - a)}{(b - a)} = \epsilon
    \end{align} 
    De donde se conclye, puesto que $\epsilon$ es arbitrario, que $\lim_{n\to\infty} \int_{a}^{b} f_n(t)dt = \int_{a}^{b} f(t)dt$
\end{proof}

\begin{prop}
    Sean $f_n$ funciones de clase $C^{1}$ en $[a, b]$ tal que $f_n \rightarrow f$ y $f_n' \rightrightarrows g$. Entonces, $f$ es derivable y $f' = g$
\end{prop}

\begin{proof}
    Las $f_n$ son de clase $C^{1}$ por lo que aplicando el TFC se tiene que $f_n(x) - f_n(a) = \int_{a}^{x} f_n'(t)dt$, aplicando límite a ambos términos se llega a que $f(x) - f(a) = \int_{a}^{x} g(t)dt$, y nuevamente aplicando el TFC se derivan ambos términos y se obtiene que $f'(x) = g(x)$
\end{proof}

\begin{definition}
    Una sucesión $(f_n)$ de funciones de $A \rightarrow Y$ es uniformemente de Cauchy si dado $\epsilon > 0$, existe $n_0 \in \mathbb{N}$ tal que $d'(f_n(x), f_m(x)) < \epsilon, \forall n, m \geq n_0, \forall x \in A$
\end{definition}

\begin{theorem}
    Si la sucesión $(f_n)$ de funciones de $A \rightarrow \mathbb{R}$ es uniformemente de Cauchy, entonces converge uniformemente a una función $f: A \rightarrow \mathbb{R}$
\end{theorem}
\begin{proof}
    Si fijamos $x \in A$ se obtiene una sucesión $(f_n(x))_{n\in \mathbb{N}}$ de números reales que es de Cauchy y por lo tanto converge, ya que $\mathbb{R}$ es un espacio métrico completo. Y como $x$ era arbitrario se sigue que $\exists f : \lim_{n\to\infty} f_n = f$ \\
    Dado $\epsilon > 0, \exists n_0 : | f_n(x) - f_m(x) | < \frac{\epsilon}{2}n, \forall n, m \geq n_0, \forall x\in A$. Si se fija $n$ y se toma el límite cuando $m \rightarrow \infty$ se obtiene que $|f_n(x) - f(x)| < \frac{\epsilon}{2} < \epsilon, \forall n \geq n_0, \forall x\in A$, y por lo tanto $f_n$ converge uniformememente a $f$.
\end{proof}

La primera vez que se ve esta prueba es un poco rara, porque suena "dudoso" la veracidad de fijar el $n$ y tomar el límite respecto a otra variable, y en general en muchas otras construcciones este argumento no va a valer. Sin embargo, acá es válido porque el $n$ y el $m$ son independientes.

\begin{prop}
    Sea $K$ un conjunto compacto y $C(K) = \{ f: K \rightarrow \mathbb{R}, f \text{continua}\}$. Sea $(f_n) \subset C(K)$, entonces $(f_n)$ es uniformemente de Cauchy si y solo si $(f_n)$ es de cauchy en $\| . \|_{\infty}$
\end{prop}

\begin{proof}
    Si $(f_n)$ es uniformemente de Cauchy, $\forall \epsilon > 0, \exists n_0 : | f_n(x) - f_m(x) | < \epsilon, \forall n, m \geq n_0, \forall x \in K \iff \| f_n - f_m \|_{\infty} < \epsilon \iff (f_n)$ es de Cauchy con $\| . \|_{\infty}$, y como todas las implicaciones son si y solo si se demostró lo pedido.
\end{proof}

\begin{theorem}
    El espacio métrico dado por $(C(K), \| . \|_{\infty})$ es completo.
\end{theorem}

\begin{proof}
    Sea $(f_n) \subset C(K)$ una sucesión de Cauchy, luego $(f_n)$ es uniformemente de Cauchy, por lo tanto $f_n \rightrightarrows f$, además como todas las funciones son continuas por el teorema \ref{thm:continuous-function-convergence} se sigue que $f$ es continua y por ende $f \in C(K)$, por lo que el espacio métrico es completo.
\end{proof} 

\begin{prop}
    Sean $(f_n)$ una familia de funciones con $f_n: A \rightarrow \mathbb{R}$ acotada, si $(f_n) \rightrightarrows f$, entonces $f$ está acotada. 
\end{prop}

\begin{proof}
    Por definición de convergencia uniforme se tiene que $\forall \epsilon > 0, \exists n_0 \in \mathbb{N} : | f - f_n | < \epsilon, \forall n \geq n_0$. En particular para $\epsilon = 1, \exists n_0 \in \mathbb{N} : | f - f_{n_0} | < 1 \Rightarrow | f(x) | < |f_{n_0}(x)| + 1, \forall x\in A$ y por ende $f$ está acotada. 
\end{proof}

\begin{prop}
    Sea $(X, d)$ un espacio métrico y sea $B(X) = \{ f: X \rightarrow R, f \text{acotada} \}$. Y sea $(B(X), \| . \|_{\infty})$ espacio métrico, entonces $B(X)$ es completo.
\end{prop}

\begin{proof}
    Sea $(f_n) \subset B(X)$ una sucesión de Cauchy, luego $f_n \rightrightarrows f$ por la propiedad 8.3 (referenciar), y por lo tanto $f$ está acotada por la propiedad anterior, es decir $f \in B(X)$, por lo que el espacio métrico es completo.
\end{proof}

Una parte fundamental del estudio de las sucesiones es el estudio de las series, es decir, estudiar las sucesiones de sumas parciales. Ese mismo estudio se puede hacer con las sucesiones de funciones y tiene sentido analizar las series de funciones (tema que entiendo va a ser fundamental para el análisis funcional y cuando veamos series de Fourier)

\begin{definition}
    Sea $E$ un espacio de Banach y $(x_n) \subset E$ una sucesión. Se define la N-ésima suma parcial de $(x_n)$ como $S_N = \sum_{n=1}^{N} x_n$. La sucesión $(S_N)$ es la sucesión de las sumas parciales de $(x_n)$
\end{definition}

\begin{definition}
    Decimos que la serie $\sum_{n=1}^{\infty} x_n$ converge cuando existe el límite $\lim_{N\to\infty}S_N = \lim_{N\to\infty}\sum_{n=1}^{N}x_n$. A ese límite, que es un elemento de $E$, se lo nota justamente $\sum_{n=1}^{\infty}x_n$.
\end{definition}

\begin{definition}
    Se dice que la serie $\sum_{n=1}^{\infty}x_n$ converge absolutamente en $E$ si $\sum_{n=1}^{\infty}\|x_n\| < +\infty$
\end{definition}

Gran parte del estudio de las series es entender bajo que criterios convergen y poder tener herramientas para saber si una serie en particular converge, esto no es el tema de esta materia pero de todas formas mostramos dos simples criterios de convergencia.

\begin{prop}
    Sea $E$ un espacio de Banach y $(x_n) \subset E$ una sucesión. Si la serie $\sum_{n=1}^{\infty}x_n$ converge absolutamente, entonces converge.
\end{prop}

\begin{proof}
    Como la serie absoluta converge se tiene que $\overline{S} = \sum_{n=1}^{N} \| x_n \|$ es una sucesión de Cauchy, por lo que dado $\epsilon > 0, \exists n_0 \in \mathbb{N} : | \overline{S_n} - \overline{S_m} | < \epsilon, \forall n, m \geq n_0$. Sea $S_M, S_N$ las sumas parciales de la sucesión $(x_n)$, con $M \geq N$. Se tiene que $\| S_M - S_N \| = \| \sum_{n=N+1}^{M} x_n \| \leq \sum_{n=N+1}^{M} \| x_n \| = | \overline{S_M} - \overline{S_N} | < \epsilon, \forall M, N \geq n_0$. Por lo tanto la sucesion $(S_N)$ es de Cauchy y como $E$ es un espacio métrico de Banach, en particular es un espacio completo, por lo que $(S_N)$ converge, es decir la serie $\sum_{n=1}^{\infty} x_n$ converge. 
\end{proof}

(REVISAR CLARIDAD DE ESTA DEMOSTRACIÓN)

\begin{theorem}[Criterio de Weierstrass]
    Sea $(f_n)$ con $f_n: X\rightarrow \mathbb{R}$ una sucesión de funciones. Si existe $(c_n)$ con $c_n \geq 0$ otra sucesión tal que $|f_n(x)| \leq c_n, \forall x\in X$ y además $\sum_{n=1}^{\infty} c_n$ converge, entonces la serie $\sum_{n=1}^{\infty}f_n$ converge absolutamente y uniformemente a una función acotada de $X \rightarrow \mathbb{R}$
\end{theorem}

\begin{proof}
    Como las $f_n$ están acotadas se tiene que $f_n \in B(X), \forall n\in \mathbb{N}$, y como $B(X)$ es un espacio métrico completo basta con mostrar que la sucesión de sumas parciales es de Cauchy. Sea $(C_N)$ la sucesión de sumas parciales de $(c_n)$, entonces, como converge en $\mathbb{R}$, es de Cauchy y se tiene que dado $\epsilon > 0, \exists n_0 \in \mathbb{N} : | C_M - C_N | < \epsilon, \forall M, N \geq n_0$. Sea $(F_N)$ la sucesión de sumas parciales de $(f_n)$, sea $M \geq N$, entonces $|F_M - F_N| = |\sum_{n=N+1}^{M} f_n | \leq \sum_{n=N+1}^{M} |f_n| \leq \sum_{n=N+1}^{M} c_n = |C_M - C_N| < \epsilon, \forall M, N \geq n_0$. Por lo tanto la serie converge uniformemente a $f \in B(X)$ y también lo hace de forma absoluta.
\end{proof}
\section{Teoría de la medida}

Ya estamos por llegar al climax de esta materia, donde definimos esta nueva forma de integrar distinta a la propuesta por Riemann, que consiste en la idea de agarrar una función fijar un punto de la imagen y para ver cuanto aporte ese pedazo a la integral, lo multiplicamos por la medida de la preimagen de ese punto. Como muestra la imagen inferior. Pero antes de lanzarnos a estudiar esta integral hay que prestar atención y ver que antes es necesario saber medir conjuntos en $\mathbb{R}$.

\begin{definition}
    Sea $X$ un conjunto y $A$ una familia de subconjuntos de $X$, es decir $A \subset \mathcal{P}(X)$. Se dice que $A$ es una $\sigma$-álgebra si es cerrada por complementos y  uniones numerables. Es decir:
    \begin{itemize}
        \item Si $a\in A \Rightarrow a^{c} = X \setminus a \in A$
        \item Si $a_n \in A, \forall n\in \mathbb{N} \Rightarrow \cup_{n\in \mathbb{N}}a_n \in A$
    \end{itemize}
\end{definition}

\begin{definition}
    Si $U = (a, b), a<b$, su longitud está definida por:
    \[
        \text{long}(U) = \begin{cases}
            b - a & \text{Si }a, b \text{ son finitos}  \\
            +\infty & \text{Si alguno es infinito} 
        \end{cases}
    \]
\end{definition}

\begin{definition}
    Se dice que $A \subset \mathbb{R}$ es un conjunto nulo si para todo $\epsilon > 0$ existen contables intervalos abiertos $(U_n)_{n\in J}$ tales que:
    \[
        A \subset \bigcup_{n \in J}U_n,  \sum_{n\in J} \text{long}(U_n) < \epsilon
    \]
\end{definition}

(ME GUSTARÍA MEJOR FORMATO PARA ESTO)

\begin{definition}
    La $\sigma$-álgebra $\mathcal{M}$ generada por los intervalos abiertos y los conjuntos nulos de $\mathbb{R}$ es la $\sigma$-álgebra de los conjuntos medibles de Lebesgue.
\end{definition}

\begin{theorem}
    Existe una única función $\mu: \mathcal{M} \rightarrow [0, +\infty]$ tal que:
    \begin{itemize}
        \item Si $A = (a, b) \Rightarrow \mu(A) = b - a$
        \item Si $A_n \in \mathcal{M}, \forall n\in \mathbb{N} \Rightarrow \mu(\bigcup_{n\in \mathbb{N}}A_n) \leq \sum_{n\in \mathbb{N}}\mu(A_n)$
        \item Si $A_n \in \mathcal{M}, \forall n\in \mathbb{N}, A_i \cap A_j = \emptyset, \forall i \neq j \Rightarrow \mu(\bigcup_{n\in \mathbb{N}}A_n) = \sum_{n\in \mathbb{N}}\mu(A_n)$ ($\sigma$-aditividad de la medida)
        \item Si $A\in\mathcal{M} \Rightarrow \mu(A) = inf\{ \mu(U) : A \subset U, U \text{conjunto abierto} \}$ (regularidad de la medida)
    \end{itemize}
\end{theorem}

En esta materia este teorema se toma así y no se ve su demostración, si se quiere se puede buscar en internet o cursar la materia cálculo avanzado de matemáticas. 

\begin{observacion}
    $\mu(\emptyset) = 0$
\end{observacion}

\begin{proof}
    Sea $A_1 = (0, 1), A_n = \emptyset, \forall n \geq 2$. Como esta familia de conjuntos es disjunta dos a dos (el vacío intersección lo que sea es vacío), por la $\sigma$-aditividad de la medida se tiene que $\mu(\bigcup_{n\in \mathbb{N}}A_n) = \sum_{n=1}^{\infty}\mu(A_n) \Rightarrow \mu((0, 1)) = \mu((0, 1)) + \sum_{n=2}^{\infty}\mu(A_n) \Rightarrow \sum_{n=2}^{\infty}\mu(\emptyset) = 0 \Rightarrow \mu(\emptyset) = 0$
\end{proof}

\begin{prop}
    Todo abierto de $\mathbb{R}$ se puede expresar como una unión contable de intervalos abiertos. 
\end{prop}

\begin{proof}
    Sea $V\subset \mathbb{R}$ un conjunto abierto. Dado $x\in V, \exists \epsilon > 0 : (x - \epsilon, x + \epsilon) \subset V$. Sea $I_x$ el mayor intervalo abierto tal que $x\in I_x \subset V$. Sean $x, y \in V$, entonces $x\in I_x, y\in I_y \Rightarrow I_x \cap I_y = \emptyset \lor I_x = I_y$, supongamos que esto no fuera así, es decir, sin perdida de generalidad, $I_x = (a, b), I_y = (\overline{a}, \overline{b})$, con $a < \overline{a} < b < \overline{b}$, luego $\overline{I}_x = (a, \overline{b})$ cumple que $x\in \overline{I}_x \land \text{long}(I_x) < \text{long}(\overline{I}_x)$, absurdo!. Resulta que $V = \cup_{x\in V} I_x$ y en particular podemos eliminar los conjuntos repetidos y se obtiene que $V = \cup_{j\in J}I_{x_j}$, y finalmente resulta que son contables (pués no puede haber una familia no contable de intervalos abiertos disjuntos en $R$, ejercicio 17 de la práctica 2).
\end{proof}

\begin{observacion}
    Por esta última propiedad resulta que todo $A$ conjunto abierto es contable, es decir, $A\in\mathcal{M}$, y por ende también todo conjunto cerrado.
\end{observacion}

\begin{prop}
    Sea $\mu: \mathcal{M}\rightarrow [0, +\infty]$ la medida de Lebesgue. Entonces, $\mu$ satisface las siguientes propiedades:
    \begin{itemize}
        \item Si $A, B \in \mathcal{M}, A \subset B \Rightarrow \mu(A) \leq \mu(B)$ (Monotonía de la medida)
        \item $A \subset \mathbb{R}$ es un conjunto nulo $\iff$ $\mu(A) = 0$
        \item Dados $A \in\mathcal{M}, c\in \mathbb{R}$, se tiene que $A + c \in \mathcal{M} \land \mu(A + c) = \mu(A)$ (Invariante por translación de la medida)
    \end{itemize}
\end{prop}
\begin{proof}
    Si $A, B \in \mathcal{M}, A\subset B \Rightarrow \mu(B) = \mu(B\setminus A) + \mu(A) \Rightarrow \mu(A) \leq \mu(B)$ \\ \\
    Si $A$ es un conjunto nulo, $\forall \epsilon > 0, \exists U_n, n\in \mathbb{N} : A \subset \cup_{n\in \mathbb{N}} U_n \land \sum_{n=1}^{\infty} \mu(U_n) < \epsilon$, por lo tanto por la monotonía de la medida, al ser la union de intervalos un conjunto abierto y por tanto medible, se tiene que $\forall \epsilon>0, \exists \overline{U}_{\epsilon} : \mu(A) \leq \mu(\overline{U}_{\epsilon}) < \epsilon \Rightarrow \mu(A) = 0$. De forma similar si $\mu(A) = 0$, por la regularidad de la medida, $\forall \epsilon > 0, \exists U$ conjunto abierto tal que $A \subset U \land \mu(U) < \epsilon$ y como ya vimos que todo abierto se puede expresar como unión numerable de intervalos abiertos se tiene que $A$ es un conjunto nulo. \\ \\

    Si $A$ es un intervalo, digamos $A = (a, b)$ es inmediato, puesto que $\mu((a + c, b + c)) = (b + c) - (a + c) = (b - a) = \mu((a, b))$. Ahora por la regularidad de la medida, por cada $U$ conjunto abierto tal que $A \subset U$, como $U$ se puede expresar como una unión contable de intervalos abiertos se sigue que $\mu(U + c) = \mu(U)$. Además notemos que si $x \in (z, y) \subset U\Rightarrow x+c \in (z+c, y+c) \subset U+c \Rightarrow A + c \subset U + c$. Por lo tanto, teniendo en cuenta la propiedad de ínfimos de abiertos de la medida se sigue que $\mu(A) \geq \mu(A + c)$, pero ahora aplicando este mismo argumento con $(A + c) - c$ se sigue que $\mu(A + c) \geq \mu((A + c) - c) = \mu(A)$, y finalmente $\mu(A) = \mu(A + c)$.
\end{proof}

\begin{prop}
    Sean $A, B \in \mathcal{M} \Rightarrow A \setminus B \in \mathcal{M}, \mu(A\cup B) = \mu(A\setminus B) + \mu(B)$. En particular, si $B \subset A$ y $\mu(B) < \infty$, entonces $\mu(A\setminus B) = \mu(A) - \mu(B)$
\end{prop}
\begin{proof}
    Por definición, como $A\cup B = (A\setminus B) \cup B$ y como $(A\setminus B) \cap B = \emptyset$, entonces vale $\mu(A\cup B) = \mu(A\setminus B) + \mu(B)$. Si además se cumple la segunda hipótesis esa ecuación se vuelve $\mu(A) = \mu(A\setminus B) + \mu(B)$, y como $\mu(B) < \infty$ se puede pasar restando para obtener $\mu(A) - \mu(B) = \mu(A\setminus B)$
\end{proof}

\begin{prop}[Regularidad por cerrados]
    Sea $A \in \mathcal{M}$, entonces $\forall \epsilon > 0, \exists F \subset A$ con $F$ conjunto cerrado tal que $\mu(A\setminus F) < \epsilon$
\end{prop}

\begin{proof}
    
\end{proof}

\begin{theorem}[Continuidad de la medida]
    Sea $\{ A_n \}_{n\in \mathbb{N}} \subset \mathcal{M}$ tal que $A_1 \subset A_2 \subset ... \subset A_n \subset ...$, entonces:
    \[
        \mu(\cup_{n\in \mathbb{N}} A_n) = \lim_{n\to\infty}\mu(A_n)
    \]
    A su vez, sea $\{ B_n \}_{n\in \mathbb{N}} \subset \mathcal{M}$ tal que $B_1 \supset B_2 \supset ... \supset B_n \supset ...$, y supongamos que existe $n_0 \in \mathbb{N}$ con $\mu(B_{n_0}) < \infty$, entonces:
    \[
        \mu(\cap_{n\in \mathbb{N}}B_n) = \lim_{n\to\infty}\mu(B_n)
    \]
\end{theorem}
\begin{proof}
    
\end{proof}

\begin{theorem}[Conjunto de Cantor]
    Todo conjunto numerable es nulo, pero no todo conjunto nulo es numerable.
\end{theorem}

(ESTE TEOREMA PROBABLEMENTE TENGA MÁS SENTIDO INTRODUCIRLO ANTES)

\section{Integral de Lebesgue}

Ya casi estamos en condiciones de introducir propiamente a la integral de Lebesge, ya sabemos como medir conjuntos y ya queremos ir a demostrar todos los teoremas y propiedades que cumple esta nueva integral. Pero... antes de eso hay que dedicarle un poco de tiempo a considerar cuales son las funciones medibles, lo que de hecho nos va a dar mucha intuición sobre que es lo que va a hacer la integral.

\begin{definition}
    Dado $A\subset \mathbb{R}$, la función característica $\chi_A: \mathbb{R} \rightarrow \mathbb{R}$ se define como:
    \[
        \chi_A(x) = \begin{cases}
            1 & x \in A \\
            0 & x \not\in A
        \end{cases}
    \]
\end{definition}

\begin{definition}
    Sea $E \subset \mathbb{R}$, una partición de $E$ es una colección de conjuntos $\{ E_n \}$ disjuntos dos a dos tales que 
    \[
        E = \bigcup_{n\in \mathbb{N}}E_n
    \]
    Si $E$ es medible, se dice que la partición es medible si cada $E_n$ es medible. 
\end{definition}

\begin{definition}
    Una función $f: E \subset \mathbb{R} \rightarrow \mathbb{R}$ se dice simple si existe una partición de $E$ en finitos conjuntos $E_1, ..., E_N$ y números $\alpha_1, ..., \alpha_N$ tales que: \[
        f(x) = \sum_{n=1}^{N}\alpha_n\chi_{E_n}(x)
    \]
    Además, si los $E_n$ son intervalos, se dice que $f$ es simple escalonada o escalonada a secas.
\end{definition}

\begin{definition}
    Se dice que una propiedad vale en casi todo punto si el conjunto de los $x$ en los que no vale esta propiedad tiene medida $0$.
\end{definition}


\begin{definition}
    Sean $E\in\mathcal{M}$ y $f: E \rightarrow \mathbb{R}\cup \{\pm\infty\}$. Se dice que $f$ es medible si $\forall a\in \mathbb{R}$ el conjunto $\{x\in E : f(x) \leq a\} = f^{-1}((-\infty, a))$ es medible.
\end{definition}

\begin{prop}
    Sea $E$ medible y $f: E \rightarrow \mathbb{R}\cup \{\pm\infty\}$. Resultan equivalentes:
    \begin{itemize}
        \item $f$ es medible
        \item $\forall a\in \mathbb{R}$, el conjunto $\{x\in E : f(x) < a \}$ es medible
        \item $\forall a \in \mathbb{R}$, el conjunto $\{ x\in E : f(x) \geq a \}$ es medible
        \item $\forall a \in \mathbb{R}$, el conjunto $\{x\in E : f(x) > a\}$ es medible
    \end{itemize}
\end{prop}
\begin{proof}
    Si $f$ es medible, luego $\forall n\in \mathbb{N}, A_n = \{ x\in E : f(x) \leq a - \frac{1}{n}\}$ es medible y por tanto también lo es $A = \cup_{n\in \mathbb{N}}A_n$ y resulta claro que $A = \{ x\in E : f(x) < a \}$. A su vez, como $\mathcal{M}$ es una $\sigma$-álgebra se tiene que $A^{c} = \{c\in E : f(x) \geq a \}$ también es medible. Usando el mismo argumento se tiene que $\forall n \in \mathbb{N}, B_n = \{ x\in E : f(x) \geq a + \frac{1}{n}\}$ también es medible y por tanto también lo es $B = \cup_{n\in \mathbb{N}}B_n$, que cumple $B = \{x\in E : f(x) > a\}$. Para terminar el ciclo de implicaciones vemos que $B^{c} = \{x\in E : f(x) \leq a \} \Rightarrow f$ es medible. \\
    Es decir, se probó que $1) \Rightarrow 2) \Rightarrow 3) \Rightarrow 4) \Rightarrow 1)$, lo que significa que todas las proposiciones son equivalentes.
\end{proof}

\begin{theorem}[Límite de medible por funciones simples]
    Sea $f: E\rightarrow [0, +\infty]$ una función medible. Entonces, existe una sucesión de creciente $(f_n)$ de funciones simples no negativas que converge puntualmente a $f$ en $E$:
    \begin{align*} 
        0 \leq f_n(x) \leq f_{n+1}(x), \forall x\in E, n\in \mathbb{N} \\
        f(x) = \lim_{n\to\infty} f_n(x), \forall x\in E
    \end{align*}
    
    Además, si $f$ es acotada, la sucesión converge a $f$ uniformemente en $E$.
\end{theorem}
(REVISAR ALINEACIÓN DE ESTE TEOREMA)
\begin{proof}
    Para cada $n\in \mathbb{N}$ se define el conjunto $E^{n} = \{ x\in E : f(x) < n\}$ y se hace una partición de forma que $E_j^{n} = \{x\in E : \frac{j-1}{2^{n}} \leq f(x) < \frac{j}{2^{n}}\} = f^{-1}([\frac{j-1}{2^{n}}, \frac{j}{2^{n}}))$, con $1\leq j\leq n2^{n}$ y se define entonces: 
    \[
        f_n(x) = \begin{cases}
            \frac{j-1}{2^{n}} & x\in E^{n}_j \\
            n & f(x) \geq n
        \end{cases}
    \]
    Como cada $f_n$ toma finitos valores, resulta que son funciones simples y por ende toda $f_n$es medible. También se cumple que $f_n \leq f_{n+1}$. En efecto si $f_n(x) = n \Rightarrow f_{n+1}(x) \geq n$ y si $f_n(x) \neq n$, digamos que $f_n(x) = \frac{j-1}{2^{n}}$, entonces:
    \begin{align*}
        \frac{j-1}{2^{n}} \leq x < \frac{j}{2^{n}}, 1\leq j\leq n  \\
        x\in [\frac{(j-1)(2)}{2^{n+1}}, \frac{2j-1}{2^{n+1}}) \lor x\in [\frac{2j-1}{2^{n+1}}, \frac{2j}{2^{n+1}})
    \end{align*}
    Y por ende $f_{n+1}(x) \geq f_n(x)$. Finalmente, si $f(x) = \infty, f_n(x) = n, \forall n\in \mathbb{N} \Rightarrow f_n(x) \rightarrow f(x)$. Por el contario si $f(x)$ es finito, y al evaluar la función simple se tiene que $\frac{j-1}{2^{n}} \leq f(x) \leq \frac{j}{2^{n}} \Rightarrow 0 \leq | f_n(x) - f(x) | \leq \frac{1}{2^{n}}, \forall n\geq n_0 \in \mathbb{N} \Rightarrow f_n(x) \rightarrow f(x)$. \\
    Para ver la convergencia uniforme, sea $k\in \mathbb{N} : f(x) \leq k, \forall x\in E$, entonces por lo visto en el parrafo anterior, se cumple que $|f_n(x) - f(x)| \leq \frac{1}{2^{n}}, \forall n\geq k, \forall x\in E$.

\end{proof}

\begin{definition}[Integral de Lebesgue de funciones simples]
    Sean $\{ E_n \}_{i=1}^{N}$ una partición medible de $E$ y $f: E \rightarrow R$ una función simple dada por:
    \[
        f(x) = \sum_{i=1}^{N}\alpha_i \chi_{E_i}(x)
    \]
    Se define la integral de Lebesgue de $f$ como:
    \[
        \int_E fd\mu := \sum_{i=1}^{N}\alpha_i\mu(E_i)
    \]
\end{definition}

\begin{prop}
    Sean $f, g: E \rightarrow \mathbb{R}$ funciones simples y $a, b\in \mathbb{R}$, entonces:
    \begin{itemize}
        \item $\int_E(af + bg)d\mu = a\int_Efd\mu + b\int_Egd\mu$ (Linealidad)
        \item $f \leq g, \forall x\in E \Rightarrow \int_Efd\mu \leq \int_Egd\mu$ (Monotonía)
        \item $|\int_Efd\mu| \leq \int_E|f|d\mu$
    \end{itemize}
\end{prop}

\begin{proof}
    Escalares salen para afuera, pues si $f(x) = \sum_{i=1}^{N}\alpha_i\chi_{E_i}(x) \Rightarrow af(x) = \sum_{i=1}^{N}a\alpha_i\chi_{E_i}(x) \Rightarrow \int_E(af)d\mu = \sum_{i=1}^{N}a\alpha_i\mu(E_i) = a\sum_{i=1}^{N}\alpha_i\mu(E_i) = a\int_Efd\mu$. Es decir, $\int_E(af)d\mu = a\int_Efd\mu$. \\
    Es lineal, pues sea $A_{ij} = E_i \cap \overline{E}_j$, luego $f + g = \sum_{i=1}^{N}\sum_{j=1}^{M}(\alpha_i + \beta_j)\chi_{A_{ij}}$ y al evaluar la integral se obtiene:
    \begin{align*}
        \int_E(f+g)d\mu = \sum_{i=1}^{N}\sum_{j=1}^{M}(\alpha_i + \beta_j)\mu(A_{ij}) = \\
    \sum_{i=1}^{N}\sum_{j=1}^{M}\alpha_i\mu(A_{ij}) + \sum_{i=1}^{N}\sum_{j=1}^{M}\beta_j\mu(A_{ij}) = \\
    \sum_{i=1}^{N}\alpha_i\sum_{j=1}^{M}\mu(A_{ij}) + \sum_{j=1}^{N}\sum_{i=1}^{M}\beta_j\mu(A_{ij}) = \\
    \sum_{i=1}^{N}\alpha_i\mu(A_i) + \sum_{j=1}^{N}\beta_j\sum_{i=1}^{M}\mu(A_{ij}) = \\
    \int_Efd\mu + \sum_{j=1}^{N}\beta_j\mu(A_j) = \\
    \int_Efd\mu + \int_Egd\mu
    \end{align*}
    Para ver la monotonía se tiene que 
    \begin{align*}
        \int_Efd\mu = \sum_{i=1}^{N}\alpha_i\mu(E_i) = \\
        \sum_{i=1}^{N}\sum_{j=1}^{M}\alpha_i\mu(E_i\cap\overline{E}_j) \leq \\
        \sum_{i=1}^{N}\sum_{j=1}^{M}\beta_i\mu(E_i\cap\overline{E}_j) = \\
        \sum_{j=1}^{M}\beta_j\sum_{i=1}^{N}\mu(E_i\cap\overline{E}_j) = \\
        \sum_{j=1}^{M}\beta_j\mu(\overline{E}_j) = \\
        \int_Egd\mu
    \end{align*}
    Finalmente, la desigualdad triangular para el módulo se ve más directamente:
    \[
        |\int_Efd\mu| = |\sum_{i=1}^{N}\alpha_i\mu(E_i)| \leq 
        \sum_{i=1}^{N} |\alpha_i\mu(E_i)| = \sum_{i=1}^{N}|\alpha_i|\mu(E_i) = \int_E|f|d\mu
    \]
\end{proof}

\begin{definition}
    Sea $f: E\rightarrow \mathbb{R}$ una función medible tal que $f\geq 0, \forall x\in E$. Se define la integral de Lebesgue de $f$ como: 
    \[
        \int_Efd\mu := sup\{\int_E\phi d\mu : \phi \text{ es simple}, \land \ 0\leq \phi \leq f\}
    \]
\end{definition}

\begin{theorem}
    Sean $f, g: E\rightarrow \mathbb{R}$ funciones medibles y no negativas en $E$. Entones, la integral de Lebesgue cumple las siguientes propiedades:
    \begin{itemize}
        \item si $0\leq f\leq g \Rightarrow \int_Efd\mu \leq \int_Egd\mu$
        \item $\int_Efd\mu < \infty \Rightarrow f < \infty$ en casi todo punto de $E$
        \item Si $A\subset E$ es un conjunto medible $\Rightarrow \int_Afd\mu \leq \int_Efd\mu$
    \end{itemize}
\end{theorem}

\begin{proof}
    Si $\phi$ es simple y $0 \leq \phi \leq f \Rightarrow 0 \leq \phi\leq g$, por lo tanto si $t \in \{\int_E\phi d\mu : \phi \text{ es simple}, \land \ 0 \leq \phi\leq f\} \Rightarrow x \in \{\int_E\phi d\mu : \phi \text{ es simple}, \land \ 0 \leq \phi\leq g\}$, lo que significa que $\int_Efd\mu \leq \int_Egd\mu$ \\
    Si $f = \infty, \forall x \in A\subset E$, donde $A$ es un conjunto con medida no nula, se puede definir $(\phi_n)$ sucesión de funciones simples tales que $0 \leq \phi_n \leq f, \forall n\in \mathbb{N}$ como: 
    \[
        \phi_n(x) = \begin{cases}
            n & x \in A \\
            0 & x \not\in A
        \end{cases}
    \]
Entonces es claro que $\int_E\phi_n d\mu = n\mu(A)$ y que $\lim_{n\to\infty}\int_E\phi_n d\mu = \infty \Rightarrow \int_Efd\mu = \infty$, ¡absurdo! Por ende se concluye que tal conjunto $A$ de medidad no nula no puede existir. \\

Basta con ver que si $\phi: A \rightarrow \mathbb{R}$ es una función simple tal que $0\leq\phi\leq f, \forall x\in A$, entonces se puede definir $\overline{\phi}: E \rightarrow \mathbb{R}$ como:
\[
    \overline{\phi}(x) = \begin{cases}
        \phi(x) & x\in A \\
        0 & x\not\in A
    \end{cases}
\]
Que cumple $0\leq \overline{\phi}\leq f, \forall x\in E, \land \ \int_A\phi d\mu = \int_E\overline{\phi}d\mu$ y esto nos dice, al igual que en la monotonía por funciones, que $\int_Afd\mu \leq \int_Efd\mu$
\end{proof}

\begin{theorem}[Teorema de la convergencia monótona]
    Sea $(f_n)$ una sucesión de funciones medibles definidas en $E$ tales que $0\leq f_n\leq f_{n+1}, \forall n\in \mathbb{N}$. Si $f = \lim_{n\to\infty}f_n$, entonces:
    \[
        \int_Efd\mu = \lim_{n\to\infty}\int_Ef_nd\mu
    \]
\end{theorem}

Cuando escuché la explicación de este teorema no entendí nada, cuando releí la demostración que había copiado tampoco entendí nada. Lo que dice el teorema es en realidad bastante intuitivo: si uno tiene una sucesión de funciones crecientes que tienen un límite, entonces: el límite de las integrales es igual a la integral del límite. Con una imagen esto se visualiza mejor.

\begin{proof}
    Para empezar, notemos que efectivamente tanto $f = \lim_{n\to\infty}f_n$ y $\lim_{n\to\infty}\int_Ef_nd\mu$ ambos existen y esto es inmediato, puesto que el primero, el límite puntual, es una sucesión creciente en $\mathbb{R}$ que converge (o eventualmente es $+\infty$ que también está bien) y el segundo es también una sucesión de números reales creciente (que nuevamente puede ser eventualmente $+\infty$). \\
    Como suele ocurrir en las igualdades, vamos a demostrarla con la doble desigualdad. \\
    Notemos que $\int_Ef_nd\mu \leq \int_Efd\mu, \forall n\in \mathbb{N} \Rightarrow \lim_{n\to\infty}\int_Ef_nd\mu \leq \int_Efd\mu$, y ya se tiene la primera desigualdad. \\
    Ahora, para la otra dirección, recordando que $\int_Efd\mu = sup\{ \int_E \phi d\mu : \phi \text{ es simple } \land \ 0\leq\phi\leq f \}$, la estrategia va a ser mostrar que dado cualquier $\phi$ en ese conjunto existe un $n_0$ para el cual $f_{n_0} \geq \phi$. Sin embargo, esto no va a ser tan automático porque la convergencia de las $(f_n)$ es puntual, no uniforme. Sea $\phi : 0\leq\phi\leq f$ una función simple y $\alpha : 0<\alpha<1$, luego defino $E_n = \{ x\in E : f_n \geq \alpha\phi \}$, como las $f_n$ son crecientes se tiene que $E_n \subset E_{n+1}$ y a su vez como $\alpha\phi < f \Rightarrow \cup_{n\in \mathbb{N}}E_n = E$. Entonces para cada $n\in \mathbb{N}$ se cumple $\int_Ef_nd\mu \geq \int_{E_n}f_nd\mu \geq \int_{E_n}\alpha\phi d\mu$ y por lo tanto:
    \begin{align*}
        \lim_{n\to\infty}\int_Ef_nd\mu \geq \lim_{n\to\infty}\int_{E_n}\alpha\phi d\mu = \lim_{n\to\infty}\sum_{i=1}^{M}\alpha \beta_i\mu(A_i\cap E_n) = \\ \sum_{i=1}^{M}\alpha\beta_i\mu(A_i) = \alpha\int_E\phi d\mu
    \end{align*}
    Notar que la última igualdad en donde se hace el paso al límite vale por la continuidad de la medidad (revisar propiedad). Finalmente como la $\phi$ era arbitraría y $0<\alpha<1$ se concluye que $\int_Efd\mu \leq \lim_{n\to\infty}\int_Ef_nd\mu$. Juntando ambas desigualdades se concluye:
    \[
        \lim_{n\to\infty}\int_Ef_nd\mu = \int_E\lim_{n\to\infty}f_nd\mu
    \]
\end{proof}

Realmente dura demostración.

\begin{prop}
    Sea $f\geq 0$ medible definida en $E$. Entonces, $\int_Efd\mu = 0 \iff f = 0$ en casi todo punto de $E$.
\end{prop}

\begin{proof}
    $\Rightarrow)$ Sea $E_n := \{x\in E : f(x) \geq \frac{1}{n} \}, \forall n\in \mathbb{N}$. Es claro que $E_n$ es medible para todo $n$ y sea $\phi_n = \frac{1}{n}\chi_{E_n}$, que es una función simple con $0\leq\phi_n\leq f$. Por la monotonía de la integral se sigue que $0\leq\int_E\phi_n d\mu \leq \int_E fd\mu \Rightarrow \frac{1}{n}\mu(E_n) = 0, \forall n\in \mathbb{N}$. Es decir, $\mu(E_n) = 0, \forall n\in \mathbb{N}$. Y a su vez $\cup_{n=1}^{\infty}E_n = \{ x\in E : f(x) > 0 \}$, lo que quiere decir $\mu(\{x\in E:f(x) > 0\}) = \mu(\cup_{n=1}^{\infty}E_n) \leq \sum_{n=1}^{\infty}\mu(E_n) = 0 \Rightarrow \mu(\{x\in E:f(x) > 0\}) = 0$, y por lo tanto $f$ vale $0$ en casi todo punto. \\
    $\Leftarrow)$ Si $f$ vale $0$ en casi todo punto de $E$, toda función simple $0\leq \phi\leq f$ va a cumplir $\int_E\phi d\mu \leq 0 + \alpha_N\mu(A)$, con $\mu(A) = 0 \Rightarrow \int_E\phi d\mu = 0$. Por lo tanto $\int_Efd\mu = 0$.
\end{proof}

Ya probamos que la integral es lineal sobre funciones simples y ahora vamos a extender ese resultado a todas las funciones medibles positivas utilizando ese hecho.
\begin{theorem}[Linealidad de la integral]
    
    Sean $f, g \geq 0$ funciones medibles con $f, g: E \rightarrow R\cup\{\pm\infty\}$. Y sea $c\in \mathbb{R}$, entonces:
    \begin{itemize}
        \item $\int_Ecfd\mu = c\int_Efd\mu$ 
        \item $\int_E(f + g)d\mu = \int_Efd\mu + \int_Egd\mu$
    \end{itemize}
\end{theorem}

\begin{proof}
    La primera propiedad es inmediata puesto que es propiedad del supremo que $sup(cA) = c\cdot sup(A)$. \\
    Por la propiedad (REFERENCIAR PROPIEDAD), existen $(f_n), (g_n):E \rightarrow \mathbb{R}$ tales que $0\leq f_n \leq f, 0\leq g_n\leq g, \forall n\in \mathbb{N}$, y además $f_n\uparrow f, g_n\uparrow g$. Por lo tanto $(f_n + g_n) \uparrow (f + g)$.Usando el teorema de la convergencia monótona (REFERENCIAR), se tiene que:
    \begin{align*}
        \int_E(f+g)d\mu = \lim_{n\to\infty}\int_E(f_n + g_n)d\mu = \lim_{n\to\infty}(\int_Ef_nd\mu + \int_Eg_nd\mu) = \\
        \lim_{n\to\infty}\int_Ef_nd\mu + \lim_{n\to\infty}\int_Eg_nd\mu = \int_Efd\mu + \int_Egd\mu
    \end{align*}
\end{proof}

\begin{theorem}[Sumatoria permuta con la integral]
    Sea $(f_n)$ una sucesión de funciones medibles definidas en $E$, tales que $f_n \geq 0, \forall n\in \mathbb{N}$, entonces:
    \[
        \int_E\sum_{n=1}^{\infty}f_nd\mu = \sum_{n=1}^{\infty}\int_Ef_nd\mu
    \]
\end{theorem}

\begin{proof}
    Sea $S_N = \sum_{n=1}^{N}f_n$, es decir la N-ésima suma parcial. Como las $f_n$ son estrictamente no negativas se tiene que la sucesión $S_N$ es creciente, de forma que se puede aplicar el teorema de la convergencía monótona y se obtiene:
    \begin{align*} 
        \int_E\sum_{n=1}^{\infty}f_nd\mu = \int_E\lim_{n\to\infty}S_nd\mu = \\
        \lim_{n\to\infty}\int_ES_nd\mu = \lim_{n\to\infty}\int_E(f_1 + f_2 + ... + f_n)d\mu = \\
        \lim_{n\to\infty}(\int_Ef_1d\mu + \int_Ef_2d\mu + ... + \int_Ef_nd\mu) = \sum_{n=1}^{\infty}\int_Ef_nd\mu
    \end{align*}
\end{proof}

\begin{lema}[Lema de Fatou]
    
    Sea $(f_n)$ una sucesión de funciones medibles definidas en $E$ tales que $f_n \geq 0, \forall n\in \mathbb{N}$, entonces:
    \[
        \int_E\liminf f_nd\mu \leq \liminf \int_Ef_nd\mu
    \]
\end{lema}

\begin{proof}
    Si $(f_n)$ es una sucesión de funciones medibles, entonces $(g_n)$ dada por $g_n = \inf_{k\geq n}f_n$, es una sucesión monótona creciente de funciones medibles. Y también resulta que $\lim_{n\to\infty}g_n = \sup(g_n) = \liminf f_n$. Por lo tanto aplicando el teorema de la convergencia monótona se cumple: 
    \[
        \lim_{n\to\infty}\int_Eg_nd\mu = \int_E\lim_{n\to\infty}g_nd\mu = \int_E\liminf f_nd\mu
    \]
    A su vez, puesto que $0 \leq g_n \leq f_n, \forall n\in \mathbb{N}$, se cumple:
    \[
        \int_Eg_nd\mu \leq \int_Ef_nd\mu \Rightarrow \lim_{n\to\infty}\int_Eg_nd\mu \leq \lim_{n\to\infty}\int_Ef_nd\mu = \liminf\int_Ef_nd\mu
    \]
    Esta última igualdad, puesto que si el límite existe entonces tanto el límite inferior y el límite superior son iguales entre sí e iguales al límite. Juntando ambas partes se tiene:
    \[
        \int_E\liminf f_nd\mu \leq \liminf\int_Ef_nd\mu
    \]
\end{proof}

\begin{theorem}[Teorema de la convergencia dominada]
    Sea $(f_n)$ una sucesión de funciones medibles definidas en $E$, tales que $f_n\geq 0, \forall n\in \mathbb{N}$. Supongamos que $f = \lim_{n\to\infty}f_n$ y que existe una función $\phi$ medible definida en $E$ tal que $f_n\leq\phi, \forall n\in \mathbb{N}$. Si $\int_E\phi d\mu < \infty$, entonces:
    \[
        \lim_{n\to\infty}\int_Ef_nd\mu = \int_Efd\mu
    \]
\end{theorem}

\begin{proof}
\end{proof}

\begin{theorem}[Continuidad absoluta de la integral]
    Sea $f\geq 0$ medible definida en $E$, tal que $\int_Efd\mu < \infty$. Entonces, dado $\epsilon > 0, \exists\delta> 0$ tal que:
    \[
        A \subset E \text{ es medible } \land \mu(A) <\delta \Rightarrow \int_Afd\mu < \epsilon
    \]
\end{theorem}

\begin{proof}
    
\end{proof}

\begin{definition}
    Sea $f\geq 0$ medible. Se dice que $f$ es integrable en $E$ si $\int_Efd\mu < +\infty$.
\end{definition}

\begin{notacion}
    Sea $f$ una función medible, luego se nota:
    \[
        f^{+} := max\{f, 0\} = \begin{cases}
            f(x) & f(x) \geq 0 \\
            0 & f(x) < 0
        \end{cases}
    \]
    \[
        f^{-} := min\{f, 0\} = \begin{cases}
            0 & f(x) \geq 0 \\
            -f(x) & f(x) < 0
        \end{cases}
    \]
    De esta forma se tiene que $f = f^{+} - f^{-}, |f| = f^{+} + f^{-}$. 
\end{notacion}

\begin{definition}
    Sea $f$ una función medible. Se dice que $\int_Efd\mu$ existe si:
    \[
        \int_Ef^{+}d\mu < +\infty \ \lor \ \int_Ef^{-}d\mu < +\infty
    \]
    En ese caso se define la integral como:
    \[
        \int_Efd\mu = \int_Ef^{+} - \int_Ef^{-}d\mu
    \]
    Y se dice que $f$ es integrable en $E$ si $\int_Efd\mu$ existe y es un número finito.
\end{definition}

\begin{theorem}[Integrable Riemman implica integrable Lebesgue]
    Sea $I$ un intervalo cerrado y acotado y $f: I \rightarrow \mathbb{R}$ una función acotada. Si $f$ es integrable Riemman, entonces es integrable Lebesge y ambas integrales coinciden.
\end{theorem}
\end{document}

